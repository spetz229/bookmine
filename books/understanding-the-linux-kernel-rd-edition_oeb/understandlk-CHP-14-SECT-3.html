---
layout: page
title: "Understanding the Linux Kernel, 3rd Edition"
prev: understandlk-CHP-14-SECT-2.html
next: understandlk-CHP-14-SECT-4.html
book_path: books/understanding-the-linux-kernel-rd-edition_oeb/
---
{% include JB/setup %}
{% raw %}
<div>


<a name="understandlk-CHP-14-SECT-3"></a>
<h3 class="docSection1Title">14.3. The I/O Scheduler</h3><a name="IDX-CHP-14-3633"></a>
<a name="IDX-CHP-14-3634"></a>
<a name="IDX-CHP-14-3635"></a>
<a name="IDX-CHP-14-3636"></a>
<p class="docText1">Although block device drivers are able to transfer a single sector at a time, the block I/O layer does not perform an individual I/O operation for each sector to be accessed on disk; this would lead to poor disk performance, because locating the physical position of a sector on the disk surface is quite time-consuming. Instead, the kernel tries, whenever possible, to cluster several sectors and handle them as a whole, thus reducing the average number of head movements.</p>
<p class="docText1">When a kernel component wishes to read or write some disk data, it actually creates a <span class="docEmphasis">block device request</span>. That request essentially describes the requested sectors and the kind of operation to be performed on them (read or write). However, the kernel does not satisfy a request as soon as it is createdthe I/O operation is just scheduled and will be performed at a later time. This artificial delay is paradoxically the crucial mechanism for boosting the performance of block devices. When a new block data transfer is requested, the kernel checks whether it can be satisfied by slightly enlarging a previous request that is still waiting (i.e., whether the new request can be satisfied without further seek operations). Because disks tend to be accessed sequentially, this simple mechanism is very effective.</p>
<p class="docText1">Deferring requests complicates block device handling. For instance, suppose a process opens a regular file and, consequently, a filesystem driver wants to read the corresponding inode from disk. The block device driver puts the request on a queue, and the process is suspended until the block storing the inode is transferred. However, the block device driver itself cannot be blocked, because any other process trying to access the same disk would be blocked as well.</p>
<p class="docText1">To keep the block device driver from being suspended, each I/O operation is processed asynchronously. In particular, block device drivers are interrupt-driven (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-13-SECT-4.html#understandlk-CHP-13-SECT-4.3">Monitoring I/O Operations</a>" in the previous chapter): the generic block layer invokes the <span class="docEmphasis">I/O scheduler</span> to create a new block device request or to enlarge an already existing one and then terminates. The block device driver, which is activated at a later time, invokes the <span class="docEmphasis">strategy routine</span> to select a pending request and satisfy it by issuing suitable commands to the disk controller. When the I/O operation terminates, the disk controller raises an interrupt and the corresponding handler invokes the strategy routine again, if necessary, to process another pending request.</p>
<p class="docText1">Each block device driver maintains its own <span class="docEmphasis">request queue</span>, which contains the list of pending requests for the device. If the disk controller is handling several disks, there is usually one request queue for each physical block device. I/O scheduling is performed separately on each request queue, thus increasing disk performance.</p>
<a name="understandlk-CHP-14-SECT-3.1"></a>
<h4 class="docSection2Title">14.3.1. Request Queue Descriptors</h4><a name="IDX-CHP-14-3637"></a>
<a name="IDX-CHP-14-3638"></a>
<a name="IDX-CHP-14-3639"></a>
<p class="docText1">Each request queue is represented by means of a large <tt class="calibre25">request_queue</tt> data structure whose fields are listed in <a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-TABLE-6">Table 14-6</a>.</p>
<a name="understandlk-CHP-14-TABLE-6"></a><p class="calibre14"><table cellspacing="0" frame="hsides" rules="all" cellpadding="4" width="100%" class="calibre15"><caption class="calibre33"><h5 class="docFigureTitle">Table 14-6. The fields of the request queue descriptor</h5></caption><colgroup class="calibre16"><col class="calibre17"/><col class="calibre17"/><col class="calibre17"/></colgroup><thead class="calibre18"><tr class="calibre34"><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Type</span></p></th><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Field</span></p></th><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Description</span></p></th></tr></thead><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct list_head</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">queue_head</tt></p></td><td class="docTableCell"><p class="docText2">List of pending requests</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct request *</tt></p></td><td class="docTableCell"><p class="docText2">last_merge</p></td><td class="docTableCell"><p class="docText2">Pointer to descriptor of the request in the queue to be considered first for possible merging</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">elevator_t *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">elevator</tt></p></td><td class="docTableCell"><p class="docText2">Pointer to the elevator object (see the later section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3.4">I/O Scheduling Algorithms</a>")</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct request_list</tt></p></td><td class="docTableCell"><p class="docText2">rq</p></td><td class="docTableCell"><p class="docText2">Data structure used for allocation of request descriptors</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">request_fn_proc *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">request_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method that implements the entry point of the strategy routine of the driver</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">merge_request_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">back_merge_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method to check whether it is possible to merge a bio to the last request in the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">merge_request_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">front_merge_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method to check whether it is possible to merge a bio to the first request in the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">merge_requests_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">merge_requests_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method to attempt merging two adjacent requests in the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">make_request_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">make_request_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method invoked when a new request has to be inserted in the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">prep_rq_fn *</tt></p></td><td class="docTableCell"><p class="docText2">prep_rq_fn</p></td><td class="docTableCell"><p class="docText2">Method to build the commands to be sent to the hardware device to process this request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">unplug_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">unplug_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method to unplug the block device (see the section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3.3">Activating the Block Device Driver</a>" later in the chapter)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">merge_bvec_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">merge_bvec_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method that returns the number of bytes that can be inserted into an existing bio when adding a new segment (usually undefined)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">activity_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">activity_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method invoked when a request is added to a queue (usually undefined)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">issue_flush_fn *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">issue_flush_fn</tt></p></td><td class="docTableCell"><p class="docText2">Method invoked when a request queue is flushed (the queue is emptied by processing all requests in a row)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct timer_list</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">unplug_timer</tt></p></td><td class="docTableCell"><p class="docText2">Dynamic timer used to perform device plugging (see the later section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3.3">Activating the Block Device Driver</a>")</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">int</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">unplug_thresh</tt></p></td><td class="docTableCell"><p class="docText2">If the number of pending requests in the queue exceeds this value, the device is immediately unplugged (default is 4)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">unsigned long</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">unplug_delay</tt></p></td><td class="docTableCell"><p class="docText2">Time delay before device unplugging (default is 3 milliseconds)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct work_struct</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">unplug_work</tt></p></td><td class="docTableCell"><p class="docText2">Work queue used to unplug the device (see the later section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3.3">Activating the Block Device Driver</a>")</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct</p><p class="docText2">backing_dev_info</p></td><td class="docTableCell"><p class="docText2">backing_dev_info</p></td><td class="docTableCell"><p class="docText2">See the text following this table</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">void *</p></td><td class="docTableCell"><p class="docText2">queuedata</p></td><td class="docTableCell"><p class="docText2">Pointer to private data of the block device driver</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">void *</p></td><td class="docTableCell"><p class="docText2">activity_data</p></td><td class="docTableCell"><p class="docText2">Private data used by the <tt class="calibre25">activity_fn</tt> method</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned long</p></td><td class="docTableCell"><p class="docText2">bounce_pfn</p></td><td class="docTableCell"><p class="docText2">Page frame number above which buffer bouncing must be used (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-14-SECT-2.html#understandlk-CHP-14-SECT-2.3">Submitting a Request</a>" later in this chapter)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">int</p></td><td class="docTableCell"><p class="docText2">bounce_gfp</p></td><td class="docTableCell"><p class="docText2">Memory allocation flags for bounce buffers</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned long</p></td><td class="docTableCell"><p class="docText2">queue_flags</p></td><td class="docTableCell"><p class="docText2">Set of flags describing the queue status</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">spinlock_t *</p></td><td class="docTableCell"><p class="docText2">queue_lock</p></td><td class="docTableCell"><p class="docText2">Pointer to request queue lock</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct kobject</p></td><td class="docTableCell"><p class="docText2">kobj</p></td><td class="docTableCell"><p class="docText2">Embedded kobject for the request queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned long</p></td><td class="docTableCell"><p class="docText2">nr_requests</p></td><td class="docTableCell"><p class="docText2">Maximum number of requests in the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">nr_congestion_on</p></td><td class="docTableCell"><p class="docText2">Queue is considered congested if the number of pending requests rises above this threshold</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">nr_congestion_off</p></td><td class="docTableCell"><p class="docText2">Queue is considered not congested if the number of pending requests falls below this threshold</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">nr_batching</p></td><td class="docTableCell"><p class="docText2">Maximum number (usually 32) of pending requests that can be submitted even when the queue is full by a special "batcher" process</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">max_sectors</p></td><td class="docTableCell"><p class="docText2">Maximum number of sectors handled by a single request (tunable)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">max_hw_sectors</p></td><td class="docTableCell"><p class="docText2">Maximum number of sectors handled by a single request (hardware constraint)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">max_phys_segments</p></td><td class="docTableCell"><p class="docText2">Maximum number of physical segments handled by a single request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">max_hw_segments</p></td><td class="docTableCell"><p class="docText2">Maximum number of hardware segments handled by a single request (the maximum number of distinct memory areas in a scatter-gather DMA operation)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">hardsect_size</p></td><td class="docTableCell"><p class="docText2">Size in bytes of a sector</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">max_segment_size</p></td><td class="docTableCell"><p class="docText2">Maximum size of a physical segment (in bytes)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned long</p></td><td class="docTableCell"><p class="docText2">seg_boundary_mask</p></td><td class="docTableCell"><p class="docText2">Memory boundary mask for segment merging</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">dma_alignment</p></td><td class="docTableCell"><p class="docText2">Alignment bitmap for initial address and length of DMA buffers (default 511)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct</p><p class="docText2">blk_queue_tag *</p></td><td class="docTableCell"><p class="docText2">queue_tags</p></td><td class="docTableCell"><p class="docText2">Bitmap of free/busy tags (used for tagged requests)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">atomic_t</p></td><td class="docTableCell"><p class="docText2">refcnt</p></td><td class="docTableCell"><p class="docText2">Reference counter of the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">in_flight</p></td><td class="docTableCell"><p class="docText2">Number of pending requests in the queue</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">sg_timeout</p></td><td class="docTableCell"><p class="docText2">User-defined command time-out (used only by SCSI generic devices)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">sg_reserved_size</p></td><td class="docTableCell"><p class="docText2">Essentially unused</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct list_head</p></td><td class="docTableCell"><p class="docText2">drain_list</p></td><td class="docTableCell"><p class="docText2">Head of a list of requests temporarily delayed until the I/O scheduler is dynamically replaced</p></td></tr></table></p><br class="calibre7"/>
<p class="docText1">Essentially, a request queue is a doubly linked list whose elements are request descriptors<a name="IDX-CHP-14-3640"></a> 
 (that is, <tt class="calibre25">request</tt> data structures; see the next section). The <tt class="calibre25">queue_head</tt> field of the request queue descriptor stores the head (the first dummy element) of the list, while the pointers in the <tt class="calibre25">queuelist</tt> field of the request descriptor link each request to the previous and next elements in the list. The ordering of the elements in the queue list is specific to each block device driver; the I/O scheduler offers, however, several predefined ways of ordering elements, which are discussed in the later section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3">The I/O Scheduler</a>."</p>
<p class="docText1">The <tt class="calibre25">backing_dev_info</tt> field is a small object of type <tt class="calibre25">backing_dev_info</tt>, which stores information about the I/O data flow traffic for the underlying hardware block device. For instance, it holds information about read-ahead and about request queue congestion state.</p>
<a name="understandlk-CHP-14-SECT-3.2"></a>
<h4 class="docSection2Title">14.3.2. Request Descriptors</h4><a name="IDX-CHP-14-3641"></a>
<a name="IDX-CHP-14-3642"></a>
<a name="IDX-CHP-14-3643"></a>
<a name="IDX-CHP-14-3644"></a>
<a name="IDX-CHP-14-3645"></a>
<a name="IDX-CHP-14-3646"></a>
<a name="IDX-CHP-14-3647"></a>
<a name="IDX-CHP-14-3648"></a>
<a name="IDX-CHP-14-3649"></a>
<a name="IDX-CHP-14-3650"></a>
<a name="IDX-CHP-14-3651"></a>
<a name="IDX-CHP-14-3652"></a>
<a name="IDX-CHP-14-3653"></a>
<a name="IDX-CHP-14-3654"></a>
<a name="IDX-CHP-14-3655"></a>
<a name="IDX-CHP-14-3656"></a>
<a name="IDX-CHP-14-3657"></a>
<a name="IDX-CHP-14-3658"></a>
<a name="IDX-CHP-14-3659"></a>
<a name="IDX-CHP-14-3660"></a>
<a name="IDX-CHP-14-3661"></a>
<a name="IDX-CHP-14-3662"></a>
<p class="docText1">Each pending request for a block device is represented by a <span class="docEmphasis">request descriptor</span>, which is stored in the <tt class="calibre25">request</tt> data structure illustrated in <a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-TABLE-7">Table 14-7</a>.</p>
<a name="understandlk-CHP-14-TABLE-7"></a><p class="calibre14"><table cellspacing="0" frame="hsides" rules="all" cellpadding="4" width="100%" class="calibre15"><caption class="calibre33"><h5 class="docFigureTitle">Table 14-7. The fields of the request descriptor</h5></caption><colgroup class="calibre16"><col class="calibre17"/><col class="calibre17"/><col class="calibre17"/></colgroup><thead class="calibre18"><tr class="calibre34"><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Type</span></p></th><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Field</span></p></th><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Description</span></p></th></tr></thead><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct list_head</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">queuelist</tt></p></td><td class="docTableCell"><p class="docText2">Pointers for request queue list</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">unsigned long</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">flags</tt></p></td><td class="docTableCell"><p class="docText2">Flags of the request (see below)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">sector_t</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">sector</tt></p></td><td class="docTableCell"><p class="docText2">Number of the next sector to be transferred</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">unsigned long</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">nr_sectors</tt></p></td><td class="docTableCell"><p class="docText2">Number of sectors yet to be transferred in the whole request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">current_nr_sectors</p></td><td class="docTableCell"><p class="docText2">Number of sectors in the current segment of the current bio yet to be transferred</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">sector_t</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">hard_sector</tt></p></td><td class="docTableCell"><p class="docText2">Number of the next sector to be transferred</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">unsigned long</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">hard_nr_sectors</tt></p></td><td class="docTableCell"><p class="docText2">Number of sectors yet to be transferred in the whole request (updated by the generic block layer)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">unsigned int</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">hard_cur_sectors</tt></p></td><td class="docTableCell"><p class="docText2">Number of sectors in the current segment of the current bio yet to be transferred (updated by the generic block layer)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct bio *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">bio</tt></p></td><td class="docTableCell"><p class="docText2">First bio in the request that has not been completely transferred</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">struct bio *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">biotail</tt></p></td><td class="docTableCell"><p class="docText2">Last bio in the request list</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">void *</tt></p></td><td class="docTableCell"><p class="docText2"><tt class="calibre25">elevator_private</tt></p></td><td class="docTableCell"><p class="docText2">Pointer to private data for the I/O scheduler</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">int</p></td><td class="docTableCell"><p class="docText2">rq_status</p></td><td class="docTableCell"><p class="docText2">Request status: essentially, either <tt class="calibre25">RQ_ACTIVE</tt> or <tt class="calibre25">RQ_INACTIVE</tt></p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct gendisk *</p></td><td class="docTableCell"><p class="docText2">rq_disk</p></td><td class="docTableCell"><p class="docText2">The descriptor of the disk referenced by the request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">int</p></td><td class="docTableCell"><p class="docText2">errors</p></td><td class="docTableCell"><p class="docText2">Counter for the number of I/O errors that occurred on the current transfer</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned long</p></td><td class="docTableCell"><p class="docText2">start_time</p></td><td class="docTableCell"><p class="docText2">Request's starting time (in jiffies)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">nr_phys_segments</p></td><td class="docTableCell"><p class="docText2">Number of physical segments of the request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned short</p></td><td class="docTableCell"><p class="docText2">nr_hw_segments</p></td><td class="docTableCell"><p class="docText2">Number of hardware segments of the request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">int</p></td><td class="docTableCell"><p class="docText2">tag</p></td><td class="docTableCell"><p class="docText2">Tag associated with the request (only for hardware devices supporting multiple outstanding data transfers)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">char *</p></td><td class="docTableCell"><p class="docText2">buffer</p></td><td class="docTableCell"><p class="docText2">Pointer to the memory buffer of the current data transfer (<tt class="calibre25">NULL</tt> if the buffer is in high-memory)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">int</p></td><td class="docTableCell"><p class="docText2">ref_count</p></td><td class="docTableCell"><p class="docText2">Reference counter for the request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">request_queue_t *</p></td><td class="docTableCell"><p class="docText2">q</p></td><td class="docTableCell"><p class="docText2">Pointer to the descriptor of the request queue containing the request</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct request_list *</p></td><td class="docTableCell"><p class="docText2">rl</p></td><td class="docTableCell"><p class="docText2">Pointer to <tt class="calibre25">request_list</tt> data structure</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct completion *</p></td><td class="docTableCell"><p class="docText2">waiting</p></td><td class="docTableCell"><p class="docText2">Completion for waiting for the end of the data transfers (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-5-SECT-2.html#understandlk-CHP-5-SECT-2.10">Completions</a>" in <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-5.html#understandlk-CHP-5">Chapter 5</a>)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">void *</p></td><td class="docTableCell"><p class="docText2">special</p></td><td class="docTableCell"><p class="docText2">Pointer to data used when the request includes a "special" command to the hardware device</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">cmd_len</p></td><td class="docTableCell"><p class="docText2">Length of the commands in the <tt class="calibre25">cmd</tt> field</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned char []</p></td><td class="docTableCell"><p class="docText2">cmd</p></td><td class="docTableCell"><p class="docText2">Buffer containing the pre-built commands prepared by the request queue's <tt class="calibre25">prep_rq_fn</tt> method</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">data_len</p></td><td class="docTableCell"><p class="docText2">Usually, the length of data in the buffer pointed to by the <tt class="calibre25">data</tt> field</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">void *</p></td><td class="docTableCell"><p class="docText2">data</p></td><td class="docTableCell"><p class="docText2">Pointer used by the device driver to keep track of the data to be transferred</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">sense_len</p></td><td class="docTableCell"><p class="docText2">Length of buffer pointed to by the <tt class="calibre25">sense</tt> field (0 if the sense field is <tt class="calibre25">NULL</tt>)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">void *</p></td><td class="docTableCell"><p class="docText2">sense</p></td><td class="docTableCell"><p class="docText2">Pointer to buffer used for output of sense commands</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">unsigned int</p></td><td class="docTableCell"><p class="docText2">timeout</p></td><td class="docTableCell"><p class="docText2">Request's time-out</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2">struct</p><p class="docText2">request_pm_state *</p></td><td class="docTableCell"><p class="docText2">pm</p></td><td class="docTableCell"><p class="docText2">Pointer to a data structure used for power-management commands</p></td></tr></table></p><br class="calibre7"/>
<p class="docText1">Each request consists of one or more bio structures. Initially, the generic block layer creates a request including just one bio. Later, the I/O scheduler may "extend" the request either by adding a new segment to the original bio, or by linking another bio structure into the request. This is possible when the new data is physically adjacent to the data already in the request. The <tt class="calibre25">bio</tt> field of the request descriptor points to the first bio structure in the request, while the <tt class="calibre25">biotail</tt> field points to the last bio. The <tt class="calibre25">rq_for_each_bio</tt> macro implements a loop that iterates over all bios included in a request.</p>
<p class="docText1">Several fields of the request descriptor may dynamically change. For instance, as soon as the chunks of data referenced in a bio have all been transferred, the <tt class="calibre25">bio</tt> field is updated so that it points to the next bio in the request list. Meanwhile, new bios can be added to the tail of the request list, so the <tt class="calibre25">biotail</tt> field may also change.</p>
<p class="docText1">Several other fields of the request descriptor are modified either by the I/O scheduler or the device driver while the disk sectors are being transferred. For instance, the <tt class="calibre25">nr_sectors</tt> field stores the number of sectors yet to be transferred in the whole request, while the <tt class="calibre25">current_nr_sectors</tt> field stores the number of sectors yet to be transferred in the current bio.</p>
<p class="docText1">The <tt class="calibre25">flags</tt> field stores a large number of flags, which are listed in <a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-TABLE-8">Table 14-8</a>. The most important one is, by far, <tt class="calibre25">REQ_RW</tt>, which determines the direction of the data transfer.</p>
<a name="understandlk-CHP-14-TABLE-8"></a><p class="calibre14"><table cellspacing="0" frame="hsides" rules="all" cellpadding="4" width="100%" class="calibre15"><caption class="calibre33"><h5 class="docFigureTitle">Table 14-8. The flags of the request descriptor</h5></caption><colgroup class="calibre16"><col class="calibre17"/><col class="calibre17"/></colgroup><thead class="calibre18"><tr class="calibre34"><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Flag</span></p></th><th class="thead" scope="col"><p class="docText1"><span class="calibre5">Description</span></p></th></tr></thead><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_RW</tt></p></td><td class="docTableCell"><p class="docText2">Direction of data transfer: <tt class="calibre25">READ</tt> (0) or <tt class="calibre25">WRITE</tt> (1)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_FAILFAST</tt></p></td><td class="docTableCell"><p class="docText2">Requests says to not retry the I/O operation in case of error</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_SOFTBARRIER</tt></p></td><td class="docTableCell"><p class="docText2">Request acts as a barrier for the I/O scheduler</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_HARDBARRIER</tt></p></td><td class="docTableCell"><p class="docText2">Request acts as a barrier for the I/O scheduler and the device driverit should be processed after older requests and before newer ones</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_CMD</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a normal read or write I/O data transfer</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_NOMERGE</tt></p></td><td class="docTableCell"><p class="docText2">Request should not be extended or merged with other requests</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_STARTED</tt></p></td><td class="docTableCell"><p class="docText2">Request is being processed</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_DONTPREP</tt></p></td><td class="docTableCell"><p class="docText2">Do not invoke the <tt class="calibre25">prep_rq_fn</tt> request queue's method to prepare in advance the commands to be sent to the hardware device</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_QUEUED</tt></p></td><td class="docTableCell"><p class="docText2">Request is taggedthat is, it refers to a hardware device that can manage many outstanding data transfers at the same time</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_PC</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a direct command to be sent to the hardware device</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_BLOCK_PC</tt></p></td><td class="docTableCell"><p class="docText2">Same as previous flag, but the command is included in a bio</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_SENSE</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a "sense" request command (for SCSI and ATAPI devices)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_FAILED</tt></p></td><td class="docTableCell"><p class="docText2">Set when a sense or direct command in the request did not work as expected</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_QUIET</tt></p></td><td class="docTableCell"><p class="docText2">Request says to not generate kernel messages in case of I/O errors</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_SPECIAL</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a special command for the hardware device (e.g., drive reset)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_DRIVE_CMD</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a special command for IDE disks</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_DRIVE_TASK</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a special command for IDE disks</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_DRIVE_TASKFILE</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a special command for IDE disks</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_PREEMPT</tt></p></td><td class="docTableCell"><p class="docText2">Request replaces the current request in front of the queue (only for IDE disks)</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_PM_SUSPEND</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a power-management command to suspend the hardware device</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_PM_RESUME</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a power-management command to awaken the hardware device</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_PM_SHUTDOWN</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a power-management command to switch off the hardware device</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_BAR_PREFLUSH</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a "flush queue" command to be sent to the disk controller</p></td></tr><tr class="calibre2"><td class="docTableCell"><p class="docText2"><tt class="calibre25">REQ_BAR_POSTFLUSH</tt></p></td><td class="docTableCell"><p class="docText2">Request includes a "flush queue" command, which has been sent to the disk controller</p></td></tr></table></p><br class="calibre7"/>
<a name="understandlk-CHP-14-SECT-3.2.1"></a>
<h5 class="docSection3Title">14.3.2.1. Managing the allocation of request descriptors</h5><a name="IDX-CHP-14-3663"></a>
<a name="IDX-CHP-14-3664"></a>
<a name="IDX-CHP-14-3665"></a>
<a name="IDX-CHP-14-3666"></a>
<a name="IDX-CHP-14-3667"></a>
<a name="IDX-CHP-14-3668"></a>
<a name="IDX-CHP-14-3669"></a>
<a name="IDX-CHP-14-3670"></a>
<a name="IDX-CHP-14-3671"></a>
<a name="IDX-CHP-14-3672"></a>
<a name="IDX-CHP-14-3673"></a>
<a name="IDX-CHP-14-3674"></a>
<p class="docText1">The limited amount of free dynamic memory may become, under very heavy loads and high disk activity, a bottleneck for processes that want to add a new request into a request queue <tt class="calibre25">q</tt>. To cope with this kind of situation, each <tt class="calibre25">request_queue</tt> descriptor includes a <tt class="calibre25">request_list</tt> data structure, which consists of:</p>
<ul class="calibre11"><li class="calibre12"><p class="docText1">A pointer to a memory pool of request descriptors (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-8-SECT-2.html#understandlk-CHP-8-SECT-2.15">Memory Pools</a>" in <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-8.html#understandlk-CHP-8">Chapter 8</a>).</p></li><li class="calibre12"><p class="docText1">Two counters for the number of requests descriptors allocated for <tt class="calibre25">READ</tt> and <tt class="calibre25">WRITE</tt> requests, respectively.</p></li><li class="calibre12"><p class="docText1">Two flags indicating whether a recent allocation for a <tt class="calibre25">READ</tt> or <tt class="calibre25">WRITE</tt> request, respectively, failed.</p></li><li class="calibre12"><p class="docText1">Two wait queues storing the processes sleeping for available <tt class="calibre25">READ</tt> and <tt class="calibre25">WRITE</tt> request descriptors, respectively.</p></li><li class="calibre12"><p class="docText1">A wait queue for the processes waiting for a request queue to be flushed (emptied).</p></li></ul>
<p class="docText1">The <tt class="calibre25">blk_get_request( )</tt> function tries to get a free request descriptor from the memory pool of a given request queue; if memory is scarce and the memory pool is exhausted, the function either puts the current process to sleep orif the kernel control path cannot blockreturns <tt class="calibre25">NULL</tt>. If the allocation succeeds, the function stores in the <tt class="calibre25">rl</tt> field of the request descriptor the address of the <tt class="calibre25">request_list</tt> data structure of the request queue. The <tt class="calibre25">blk_put_request( )</tt> function releases a request descriptor; if its reference counter becomes zero, the descriptor is given back to the memory pool from which it was taken.</p>
<a name="understandlk-CHP-14-SECT-3.2.2"></a>
<h5 class="docSection3Title">14.3.2.2. Avoiding request queue congestion</h5>
<p class="docText1">Each request queue has a maximum number of allowed pending requests. The <tt class="calibre25">nr_requests</tt> field of the request descriptor stores the maximum number of allowed pending requests for each data transfer direction. By default, a queue has at most 128 pending read requests and 128 pending write requests. If the number of pending read (write) requests exceeds <tt class="calibre25">nr_requests</tt>, the queue is marked as full by setting the <tt class="calibre25">QUEUE_FLAG_READFULL</tt> (<tt class="calibre25">QUEUE_FLAG_WRITEFULL</tt>) flag in the <tt class="calibre25">queue_flags</tt> field of the request queue descriptor, and blockable processes trying to add requests for that data transfer direction are put to sleep in the corresponding wait queue of the <tt class="calibre25">request_list</tt> data structure.</p>
<p class="docText1">A filled-up request queue impacts negatively on the system's performance, because it forces many processes to sleep while waiting for the completion of I/O data transfers. Thus, if the number of pending requests for a given direction exceeds the value stored in the <tt class="calibre25">nr_congestion_on</tt> field of the request descriptor (by default, 113), the kernel regards the queue as <span class="docEmphasis">congested</span> and tries to slow down the creation rate of the new requests. A congested request queue becomes uncongested when the number of pending requests falls below the value of the <tt class="calibre25">nr_congestion_off</tt> field (by default, 111). The <tt class="calibre25">blk_congestion_wait( )</tt> function puts the current process to sleep until any request queue becomes uncongested or a time-out elapses.</p>
<a name="understandlk-CHP-14-SECT-3.3"></a>
<h4 class="docSection2Title">14.3.3. Activating the Block Device Driver</h4><a name="IDX-CHP-14-3675"></a>
<a name="IDX-CHP-14-3676"></a>
<a name="IDX-CHP-14-3677"></a>
<a name="IDX-CHP-14-3678"></a>
<a name="IDX-CHP-14-3679"></a>
<a name="IDX-CHP-14-3680"></a>
<a name="IDX-CHP-14-3681"></a>
<a name="IDX-CHP-14-3682"></a>
<a name="IDX-CHP-14-3683"></a>
<a name="IDX-CHP-14-3684"></a>
<a name="IDX-CHP-14-3685"></a>
<p class="docText1">As we saw earlier, it's expedient to delay activation of the block device driver in order to increase the chances of clustering requests for adjacent blocks. The delay is accomplished through a technique known as <span class="docEmphasis">device plugging</span> and <span class="docEmphasis">unplugging</span>.<sup class="docFootnote"><a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-FN2">[*]</a></sup> As long as a block device driver is plugged, the device driver is not activated even if there are requests to be processed in the driver's queues.</p><blockquote class="calibre22"><p class="docFootnote1"><sup class="calibre24"><a name="understandlk-CHP-14-FN2">[*]</a></sup> If you are confused by the terms "plugging" and "unplugging," you might consider them equivalent to "de-activating" and "activating," respectively.</p></blockquote>
<p class="docText1">The <tt class="calibre25">blk_plug_device( )</tt> function plugs a block deviceor more precisely, a request queue serviced by some block device driver. Essentially, the function receives as an argument the address <tt class="calibre25">q</tt> of a request queue descriptor. It sets the <tt class="calibre25">QUEUE_FLAG_PLUGGED</tt> bit in the <tt class="calibre25">q-&gt;queue_flags</tt> field; then, it restarts the dynamic timer embedded in the <tt class="calibre25">q-&gt;unplug_timer</tt> field.</p>
<p class="docText1">The <tt class="calibre25">blk_remove_plug( )</tt> function unplugs a request queue <tt class="calibre25">q</tt>: it clears the <tt class="calibre25">QUEUE_FLAG_PLUGGED</tt> flag and cancels the execution of the <tt class="calibre25">q-&gt;unplug_timer</tt> dynamic timer. This function can be explicitly invoked by the kernel when all mergeable requests "in sight" have been added to the queue. Moreover, the I/O scheduler unplugs a request queue if the number of pending requests in the queue exceeds the value stored in the <tt class="calibre25">unplug_thres</tt> field of the request queue descriptor (by default, 4).</p>
<p class="docText1">If a device remains plugged for a time interval of length <tt class="calibre25">q-&gt;unplug_delay</tt> (usually 3 milliseconds), the dynamic timer activated by <tt class="calibre25">blk_plug_device( )</tt> elapses, thus the <tt class="calibre25">blk_unplug_timeout( )</tt> function is executed. As a consequence, the <span class="docEmphasis">kblockd</span><a name="IDX-CHP-14-3686"></a> 
 kernel thread servicing the <tt class="calibre25">kblockd_workqueue</tt> work queue is awakened (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-4-SECT-8.html#understandlk-CHP-4-SECT-8">Work Queues</a>" in <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-4.html#understandlk-CHP-4">Chapter 4</a>). This kernel thread executes the function whose address is stored in the <tt class="calibre25">q-&gt;unplug_work</tt> data structurethat is, the <tt class="calibre25">blk_unplug_work( )</tt> function. In turn, this function invokes the <tt class="calibre25">q-&gt;unplug_fn</tt> method of the request queue, which is usually implemented by the <tt class="calibre25">generic_unplug_device( )</tt> function. The <tt class="calibre25">generic_unplug_device( )</tt> function takes care of unplugging the block device: first, it checks whether the queue is still active; then, it invokes <tt class="calibre25">blk_remove_plug( )</tt>; and finally, it executes the strategy routine<tt class="calibre25">request_fn</tt> methodto start processing the next request in the queue (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-14-SECT-4.html#understandlk-CHP-14-SECT-4.2">Device Driver Registration and Initialization</a>" later in this chapter).</p>
<a name="understandlk-CHP-14-SECT-3.4"></a>
<h4 class="docSection2Title">14.3.4. I/O Scheduling Algorithms</h4><a name="IDX-CHP-14-3687"></a>
<a name="IDX-CHP-14-3688"></a>
<p class="docText1">When a new request is added to a request queue, the generic block layer invokes the I/O scheduler to determine that exact position of the new element in the queue. The I/O scheduler tries to keep the request queue sorted sector by sector. If the requests to be processed are taken sequentially from the list, the amount of disk seeking is significantly reduced because the disk head moves in a linear way from the inner track to the outer one (or vice versa) instead of jumping randomly from one track to another. This heuristic is reminiscent of the algorithm used by elevators when dealing with requests coming from different floors to go up or down. The elevator moves in one direction; when the last booked floor is reached in one direction, the elevator changes direction and starts moving in the other direction. For this reason, I/O schedulers are also called <span class="docEmphasis">elevators</span>.</p>
<p class="docText1">Under heavy load, an I/O scheduling algorithm that strictly follows the order of the sector numbers is not going to work well. In this case, indeed, the completion time of a data transfer strongly depends on the physical position of the data on the disk. Thus, if a device driver is processing requests near the top of the queue (lower sector numbers), and new requests with low sector numbers are continuously added to the queue, then the requests in the tail of the queue can easily starve. I/O scheduling algorithms are thus quite sophisticated.</p>
<p class="docText1">Currently, Linux 2.6 offers four different types of I/O schedulersor elevatorscalled "Anticipatory," "Deadline," "CFQ (Complete Fairness Queueing)," and "Noop (No Operation)." The default elevator used by the kernel for most block devices is specified at boot time with the kernel parameter <tt class="calibre25">elevator=</tt><span class="docEmphasis">&lt;name&gt;</span>, where <span class="docEmphasis">&lt;name&gt;</span> is one of the following: <tt class="calibre25">as</tt>, <tt class="calibre25">deadline</tt>, <tt class="calibre25">cfq</tt>, and <tt class="calibre25">noop</tt>. If no boot time argument is given, the kernel uses the "Anticipatory" I/O scheduler. Anyway, a device driver can replace the default elevator with another one; a device driver can also define its custom I/O scheduling algorithm, but this is very seldom done.</p>
<p class="docText1">Furthermore, the system administrator can change at runtime the I/O scheduler for a specific block device. For instance, to change the I/O scheduler used in the master disk of the first IDE channel, the administrator can write an elevator name into the <i class="docEmphasis">/sys/block/hda/queue/scheduler</i> file of the <i class="docEmphasis">sysfs</i><a name="IDX-CHP-14-3689"></a> 
 special filesystem (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-13-SECT-2.html#understandlk-CHP-13-SECT-2.1">The sysfs Filesystem</a>" in <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-13.html#understandlk-CHP-13">Chapter 13</a>).</p>
<p class="docText1">The I/O scheduler algorithm used in a request queue is represented by an <span class="docEmphasis">elevator object</span> of type <tt class="calibre25">elevator_t</tt>; its address is stored in the <tt class="calibre25">elevator</tt> field of the request queue descriptor. The elevator object includes several methods covering all possible operations of the elevator: linking and unlinking the elevator to a request queue, adding and merging requests to the queue, removing requests from the queue, getting the next request to be processed from the queue, and so on. The elevator object also stores the address of a table including all information required to handle the request queue. Furthermore, each request descriptor includes an <tt class="calibre25">elevator_private</tt> field that points to an additional data structure used by the I/O scheduler to handle the request.</p>
<p class="docText1">Let us now briefly describe the four I/O scheduling algorithms, from the simplest one to the most sophisticated one. Be warned that designing an I/O scheduler is much like designing a CPU scheduler (see <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-7.html#understandlk-CHP-7">Chapter 7</a>): the heuristics and the values of the adopted constants are the result of an extensive amount of testing and benchmarking.</p>
<p class="docText1">Generally speaking, all algorithms make use of a <span class="docEmphasis">dispatch queue</span>, which includes all requests sorted according to the order in which the requests should be processed by the device driverthe next request to be serviced by the device driver is always the first element in the dispatch queue. The dispatch queue is actually the request queue rooted at the <tt class="calibre25">queue_head</tt> field of the request queue descriptor. Almost all algorithms also make use of additional queues to classify and sort requests. All of them allow the device driver to add bios to existing requests and, if necessary, to merge two "adjacent" requests.</p>
<a name="understandlk-CHP-14-SECT-3.4.1"></a>
<h5 class="docSection3Title">14.3.4.1. The "Noop" elevator</h5><a name="IDX-CHP-14-3690"></a>
<a name="IDX-CHP-14-3691"></a>
<a name="IDX-CHP-14-3692"></a>
<a name="IDX-CHP-14-3693"></a>
<p class="docText1">This is the simplest I/O scheduling algorithm. There is no ordered queue: new requests are always added either at the front or at the tail of the dispatch queue, and the next request to be processed is always the first request in the queue.</p>
<a name="understandlk-CHP-14-SECT-3.4.2"></a>
<h5 class="docSection3Title">14.3.4.2. The "CFQ" elevator</h5>
<p class="docText1">The main goal of the "Complete Fairness Queueing" elevator is ensuring a fair allocation of the disk I/O bandwidth among all the processes that trigger the I/O requests. To achieve this result, the elevator makes use of a large number of sorted queuesby default, 64that store the requests coming from the different processes. Whenever a requested is handed to the elevator, the kernel invokes a hash function that converts the thread group identifier of the current process (usually it corresponds to the PID, see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-3-SECT-2.html#understandlk-CHP-3-SECT-2.2">Identifying a Process</a>" in <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-3.html#understandlk-CHP-3">Chapter 3</a>) into the index of a queue; then, the elevator inserts the new request at the tail of this queue. Therefore, requests coming from the same process are always inserted in the same queue.</p>
<p class="docText1">To refill the dispatch queue, the elevator essentially scans the I/O input queues in a round-robin fashion, selects the first nonempty queue, and moves a batch of requests from that queue into the tail of the dispatch queue.</p>
<a name="understandlk-CHP-14-SECT-3.4.3"></a>
<h5 class="docSection3Title">14.3.4.3. The "Deadline" elevator</h5><a name="IDX-CHP-14-3694"></a>
<p class="docText1">Besides the dispatch queue, the "Deadline" elevator makes use of four queues. Two of themthe <span class="docEmphasis">sorted queues</span><a name="IDX-CHP-14-3695"></a> 
include the read and write requests, respectively, ordered according to their initial sector numbers. The other twothe <span class="docEmphasis">deadline queues</span><a name="IDX-CHP-14-3696"></a> 
include the same read and write requests sorted according to their "deadlines." These queues are introduced to avoid <span class="docEmphasis">request starvation</span><a name="IDX-CHP-14-3697"></a>
<a name="IDX-CHP-14-3698"></a> 
, which occurs when the elevator policy ignores for a very long time a request because it prefers to handle other requests that are closer to the last served one. A request <span class="docEmphasis">deadline</span> is essentially an expire timer that starts ticking when the request is passed to the elevator. By default, the expire time of read requests is 500 milliseconds, while the expire time for write requests is 5 secondsread requests are privileged over write requests because they usually block the processes that issued them. The deadline ensures that the scheduler looks at a request if it's been waiting a long time, even if it is low in the sort.</p>
<p class="docText1">When the elevator must replenish the dispatch queue, it first determines the data direction of the next request. If there are both read and write requests to be dispatched, the elevator chooses the "read" direction, unless the "write" direction has been discarded too many times (to avoid write requests starvation).</p>
<p class="docText1">Next, the elevator checks the deadline queue relative to the chosen direction: if the deadline of the first request in the queue is elapsed, the elevator moves that request to the tail of the dispatch queue; it also moves a batch of requests taken from the sorted queue, starting from the request following the expired one. The length of this batch is longer if the requests happen to be physically adjacent on disks, shorter otherwise.</p>
<p class="docText1">Finally, if no request is expired, the elevator dispatches a batch of requests starting with the request following the last one taken from the sorted queue. When the cursor reaches the tail of the sorted queue, the search starts again from the top ("one-way elevator").</p>
<a name="understandlk-CHP-14-SECT-3.4.4"></a>
<h5 class="docSection3Title">14.3.4.4. The "Anticipatory" elevator</h5>
<p class="docText1">The "Anticipatory" elevator is the most sophisticated I/O scheduler algorithm offered by Linux. Basically, it is an evolution of the "Deadline" elevator, from which it borrows the fundamental mechanism: there are two deadline queues and two sorted queues; the I/O scheduler keeps scanning the sorted queues, alternating between read and write requests, but giving preference to the read ones. The scanning is basically sequential, unless a request expires. The default expire time for read requests is 125 milliseconds, while the default expire time for write requests is 250 milliseconds. The elevator, however, follows some additional heuristics:</p>
<ul class="calibre11"><li class="calibre12"><p class="docText1">In some cases, the elevator might choose a request behind the current position in the sorted queue, thus forcing a backward seek of the disk head. This happens, typically, when the seek distance for the request behind is less than half the seek distance of the request after the current position in the sorted queue.</p></li><li class="calibre12"><p class="docText1">The elevator collects statistics about the patterns of I/O operations triggered by every process in the system. Right after dispatching a read request that comes from some process P, the elevator checks whether the next request in the sorted queue comes from the same process P. If so, the next request is dispatched immediately. Otherwise, the elevator looks at the collected statistics about process P: if it decides that process P will likely issue another read request soon, then it stalls for a short period of time (by default, roughly 7 milliseconds). Thus, the elevator might anticipate a read request coming from process P that is "close" on disk to the request just dispatched.</p></li></ul>
<a name="understandlk-CHP-14-SECT-3.5"></a>
<h4 class="docSection2Title">14.3.5. Issuing a Request to the I/O Scheduler</h4><a name="IDX-CHP-14-3699"></a>
<a name="IDX-CHP-14-3700"></a>
<a name="IDX-CHP-14-3701"></a>
<a name="IDX-CHP-14-3702"></a>
<a name="IDX-CHP-14-3703"></a>
<p class="docText1">As seen in the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-14-SECT-2.html#understandlk-CHP-14-SECT-2.3">Submitting a Request</a>" earlier in this chapter, the <tt class="calibre25">generic_make_request( )</tt> function invokes the <tt class="calibre25">make_request_fn</tt> method of the request queue descriptor to transmit a request to the I/O scheduler. This method is usually implemented by the <tt class="calibre25">_ _make_request( )</tt> function; it receives as its parameters a <tt class="calibre25">request_queue</tt> descriptor <tt class="calibre25">q</tt> and a <tt class="calibre25">bio</tt> descriptor <tt class="calibre25">bio</tt>, and it performs the following operations:</p>
<div class="calibre44"><ol class="docList1" type="1"><li class="calibre12"><div class="calibre45"><p class="docList">Invokes the <tt class="calibre25">blk_queue_bounce( )</tt> function to set up a bounce buffer, if required (see later). If a bounce buffer was created, the <tt class="calibre25">_ _make_request( )</tt> function operates on it rather than on the original bio.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Invokes the I/O scheduler function <tt class="calibre25">elv_queue_empty( )</tt> to check whether there are pending requests in the request queuenotice that the dispatch queue might be empty, but other queues of the I/O scheduler might contain pending requests. If there are no pending requests, it invokes the <tt class="calibre25">blk_plug_device( )</tt> function to plug the request queue (see the section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3.3">Activating the Block Device Driver</a>" earlier in this chapter), and jumps to step 5.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Here the request queue includes pending requests. Invokes the <tt class="calibre25">elv_merge( )</tt> I/O scheduler function to check whether the new bio can be merged inside an existing request. The function may return three possible values:</p><ul class="calibre61"><li class="calibre12"><p class="docList"><tt class="calibre25">ELEVATOR_NO_MERGE</tt>: the bio cannot be included in an already existing request: in that case, the function jumps to step 5.</p></li><li class="calibre12"><p class="docList"><tt class="calibre25">ELEVATOR_BACK_MERGE</tt>: the bio might be added as the last bio of some request <tt class="calibre25">req</tt>: in that case, the function invokes the <tt class="calibre25">q-&gt;back_merge_fn</tt> method to check whether the request can be extended. If not, the function jumps to step 5. Otherwise it inserts the bio descriptor at the tail of the <tt class="calibre25">req</tt>'s list and updates the <tt class="calibre25">req</tt>'s fields. Then, it tries to merge the request with a following request (the new bio might fill a hole between the two requests).</p></li><li class="calibre12"><p class="docList"><tt class="calibre25">ELEVATOR_FRONT_MERGE</tt>: the bio can be added as the first bio of some request <tt class="calibre25">req</tt>: in that case, the function invokes the <tt class="calibre25">q-&gt;front_merge_fn</tt> method to check whether the request can be extended. If not, it jumps to step 5. Otherwise, it inserts the bio descriptor at the head of the <tt class="calibre25">req</tt>'s list and updates the <tt class="calibre25">req</tt>'s fields. Then, the function tries to merge the request with the preceding request.</p></li></ul></div></li><li class="calibre12"><div class="calibre45"><p class="docList">The bio has been merged inside an already existing request. Jumps to step 7 to terminate the function.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Here the bio must be inserted in a new request. Allocates a new request descriptor. If there is no free memory, the function suspends the current process, unless the <tt class="calibre25">BIO_RW_AHEAD</tt> flag in <tt class="calibre25">bio-&gt;bi_rw</tt> is set, which means that the I/O operation is a read-ahead (see <a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-16.html#understandlk-CHP-16">Chapter 16</a>); in this case, the function invokes <tt class="calibre25">bio_endio( )</tt> and terminates: the data transfer will not be executed. For a description of <tt class="calibre25">bio_endio( )</tt>, see step 1 of <tt class="calibre25">generic_make_request( )</tt> in the earlier section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-14-SECT-2.html#understandlk-CHP-14-SECT-2.3">Submitting a Request</a>."</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Initializes the fields of the request descriptor. In particular:</p><div class="calibre44"><ol class="docList4" type="a"><li class="calibre12"><div class="calibre45"><p class="docList">Initializes the various fields that store the sector numbers, the current bio, and the current segment according to the contents of the bio descriptor.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Sets the <tt class="calibre25">REQ_CMD</tt> flag in the <tt class="calibre25">flags</tt> field (this is a normal read or write operation).</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">If the page frame of the first bio segment is in low memory, it sets the <tt class="calibre25">buffer</tt> field to the linear address of that buffer.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Sets the <tt class="calibre25">rq_disk</tt> field with the <tt class="calibre25">bio-&gt;bi_bdev-&gt;bd_disk</tt> address.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Inserts the bio in the request list.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Sets the <tt class="calibre25">start_time</tt> field to the value of <tt class="calibre25">jiffies</tt>.</p></div></li></ol></div></div></li><li class="calibre12"><div class="calibre45"><p class="docList">All done. Before terminating, however, it checks whether the <tt class="calibre25">BIO_RW_SYNC</tt> flag in <tt class="calibre25">bio-&gt;bi_rw</tt> is set. If so, it invokes <tt class="calibre25">generic_unplug_device( )</tt> on the request queue to unplug the driver (see the section "<a class="pcalibre5 docLink pcalibre1" href="#understandlk-CHP-14-SECT-3.3">Activating the Block Device Driver</a>" earlier in this chapter).</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Terminates.</p></div></li></ol></div>
<p class="docText1">If the request queue was not empty before invoking <tt class="calibre25">_ _make_request( )</tt>, either the request queue is already unplugged, or it will be unplugged soonbecause each plugged request queue <tt class="calibre25">q</tt> with pending requests has a running <tt class="calibre25">q-&gt;unplug_timer</tt> dynamic timer. On the other hand, if the request queue was empty, the <tt class="calibre25">_ _make_request( )</tt> function plugs it. Sooner (on exiting from <tt class="calibre25">_ _make_request( )</tt>, if the <tt class="calibre25">BIO_RW_SYNC</tt> bio flag is set) or later (in the worst case, when the unplug timer decays), the request queue will be unplugged. In any case, eventually the strategy routine of the block device driver will take care of the requests in the dispatch queue (see the section "<a class="pcalibre5 docLink pcalibre1" href="understandlk-CHP-14-SECT-4.html#understandlk-CHP-14-SECT-4.2">Device Driver Registration and Initialization</a>" earlier in this chapter).</p>
<a name="understandlk-CHP-14-SECT-3.5.1"></a>
<h5 class="docSection3Title">14.3.5.1. The blk_queue_bounce( ) function</h5>
<p class="docText1">The <tt class="calibre25">blk_queue_bounce( )</tt> function looks at the flags in <tt class="calibre25">q-&gt;bounce_gfp</tt> and at the threshold in <tt class="calibre25">q-&gt;bounce_pfn</tt> to determine whether <span class="docEmphasis">buffer bouncing</span><a name="IDX-CHP-14-3704"></a> 
 might be required. This happens when some of the buffers in the request are located in high memory and the hardware device is not able to address them.</p>
<p class="docText1">Older DMA for ISA buses only handled 24-bit physical addresses. In this case, the buffer bouncing threshold is set to 16 MB, that is, to page frame number 4096. Block device drivers, however, do not usually rely on buffer bouncing when dealing with older devices; rather, they prefer to directly allocate the DMA buffers in the <tt class="calibre25">ZONE_DMA</tt> memory zone.</p>
<p class="docText1">If the hardware device cannot cope with buffers in high memory, the function checks whether some of the buffers in the bio must really be bounced. In this case, it makes a copy of the bio descriptor, thus creating a <span class="docEmphasis">bounce bio</span>; then, for each segment's page frame having number equal to or greater than <tt class="calibre25">q-&gt;bounce_pfn</tt>, it performs the following steps:</p>
<div class="calibre44"><ol class="docList1" type="1"><li class="calibre12"><div class="calibre45"><p class="docList">Allocates a page frame in the <tt class="calibre25">ZONE_NORMAL</tt> or <tt class="calibre25">ZONE_DMA</tt> memory zone, according to the allocation flags.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">Updates the <tt class="calibre25">bv_page</tt> field of the segment in the bounce bio so that it points to the descriptor of the new page frame.</p></div></li><li class="calibre12"><div class="calibre45"><p class="docList">If <tt class="calibre25">bio-&gt;bio_rw</tt> specifies a write operation, it invokes <tt class="calibre25">kmap( )</tt> to temporarily map the high memory page in the kernel address space, copies the high memory page onto the low memory page, and invokes <tt class="calibre25">kunmap( )</tt> to release the mapping.</p></div></li></ol></div>
<p class="docText1">The <tt class="calibre25">blk_queue_bounce( )</tt> function then sets the <tt class="calibre25">BIO_BOUNCED</tt> flag in the bounce bio, initializes a specific <tt class="calibre25">bi_end_io</tt> method for the bounce bio, and finally stores in the <tt class="calibre25">bi_private</tt> field of the bounce bio the pointer to the original bio. When the I/O data transfer on the bounce bio terminates, the function that implements the <tt class="calibre25">bi_end_io</tt> method copies the data to the high memory buffer (only for a read operation) and releases the bounce bio.</p>
<a href="31071535.html"><img src="pixel.jpg" alt="" border="0" class="calibre19"/></a>
<br class="calibre7"/>

</div>

{% endraw %}

