---
layout: page
title: "Java Concurrency in Practice"
prev: ch11.html
next: ch11lev1sec2.html
book_path: books/brian-goetz-tim-peierls-joshua-bloch-joseph-bowbeer-david-holmes-doug-lea-java-concurrency-in-practice--_oeb/
---
{% include JB/setup %}
{% raw %}
<div>


<a name="ch11lev1sec1" class="calibre18" id="ch11lev1sec1"></a>
<h3 id="title-IDAP5HJU" class="docSection1Title">11.1. Thinking about Performance</h3>
<p class="docText1">Improving performance means doing more work with fewer resources. The meaning of "resources" can vary; for a given activity, some specific resource is usually in shortest supply, whether it is CPU cycles, memory, network bandwidth, I/O bandwidth, database requests, disk space, or any number of other resources. When the performance of an activity is limited by availability of a particular resource, we say it is <span class="docEmphasis">bound</span> by that resource: CPU-bound, database-bound, etc.</p>
<p class="docText1">While the goal may be to improve performance overall, using multiple threads always introduces some performance costs compared to the single-threaded approach. These include the overhead associated with coordinating between threads (locking, signaling, and memory synchronization), increased context switching, <a name="iddle1714" class="calibre18" id="iddle1714"></a><a name="iddle1715" class="calibre18" id="iddle1715"></a><a name="iddle2575" class="calibre18" id="iddle2575"></a><a name="iddle2660" class="calibre18" id="iddle2660"></a><a name="iddle2661" class="calibre18" id="iddle2661"></a><a name="iddle2662" class="calibre18" id="iddle2662"></a><a name="iddle2663" class="calibre18" id="iddle2663"></a><a name="iddle2664" class="calibre18" id="iddle2664"></a><a name="iddle2665" class="calibre18" id="iddle2665"></a><a name="iddle2666" class="calibre18" id="iddle2666"></a><a name="iddle2668" class="calibre18" id="iddle2668"></a><a name="iddle3185" class="calibre18" id="iddle3185"></a><a name="iddle3393" class="calibre18" id="iddle3393"></a><a name="iddle3501" class="calibre18" id="iddle3501"></a><a name="iddle3502" class="calibre18" id="iddle3502"></a><a name="iddle3503" class="calibre18" id="iddle3503"></a><a name="iddle3504" class="calibre18" id="iddle3504"></a><a name="iddle3505" class="calibre18" id="iddle3505"></a><a name="iddle3506" class="calibre18" id="iddle3506"></a><a name="iddle3524" class="calibre18" id="iddle3524"></a><a name="iddle3912" class="calibre18" id="iddle3912"></a><a name="iddle3913" class="calibre18" id="iddle3913"></a><a name="iddle4054" class="calibre18" id="iddle4054"></a><a name="iddle4074" class="calibre18" id="iddle4074"></a><a name="iddle4092" class="calibre18" id="iddle4092"></a><a name="iddle4093" class="calibre18" id="iddle4093"></a><a name="iddle4094" class="calibre18" id="iddle4094"></a><a name="iddle5035" class="calibre18" id="iddle5035"></a><a name="iddle5037" class="calibre18" id="iddle5037"></a><a name="iddle5038" class="calibre18" id="iddle5038"></a>thread creation and teardown, and scheduling overhead. When threading is employed effectively, these costs are more than made up for by greater throughput, responsiveness, or capacity. On the other hand, a poorly designed concurrent application can perform even worse than a comparable sequential one.<sup class="docFootnote"><a class="calibre2" href="#ch11fn02">[2]</a></sup></p><blockquote class="calibre19"><p class="docFootnote1"><sup class="calibre27"><a name="ch11fn02" class="calibre18" id="ch11fn02">[2]</a></sup> A colleague provided this amusing anecodote: he had been involved in the testing of an expensive and complex application that managed its work via a tunable thread pool. After the system was complete, testing showed that the optimal number of threads for the pool was . . . 1. This should have been obvious from the outset; the target system was a single-CPU system and the application was almost entirely CPU-bound.</p></blockquote>
<p class="docText1">In using concurrency to achieve better performance, we are trying to do two things: utilize the processing resources we have more effectively, and enable our program to exploit additional processing resources if they become available. From a performance monitoring perspective, this means we are looking to keep the CPUs as busy as possible. (Of course, this doesn't mean burning cycles with useless computation; we want to keep the CPUs busy with <span class="docEmphasis">useful</span> work.) If the program is compute-bound, then we may be able to increase its capacity by adding more processors; if it can't even keep the processors we have busy, adding more won't help. Threading offers a means to keep the CPU(s) "hotter" by decomposing the application so there is always work to be done by an available processor.</p>
<a name="ch11lev2sec1" class="calibre18" id="ch11lev2sec1"></a>
<h4 id="title-IDA2MCJU" class="docSection2Title">11.1.1. Performance Versus Scalability</h4>
<p class="docText1">Application performance can be measured in a number of ways, such as service time, latency, throughput, efficiency, scalability, or capacity. Some of these (service time, latency) aremeasures of "how fast" a given unit of work can be processed or acknowledged; others (capacity, throughput) are measures of "how much" work can be performed with a given quantity of computing resources.</p>
<a name="ch11sb01" class="calibre18" id="ch11sb01"></a><p class="calibre21"><table cellspacing="0" width="90%" border="1" cellpadding="5" class="calibre5"><tr class="calibre6"><td class="calibre28">
<p class="docText1"><span class="docEmphasis">Scalability</span> describes the ability to improve throughput or capacity when additional computing resources (such as additional CPUs, memory, storage, or I/O bandwidth) are added.</p>
</td></tr></table></p><p class="calibre1"> </p>
<p class="docText1">Designing and tuning concurrent applications for scalability can be very different from traditional performance optimization. When tuning for performance, the goal is usually to do the <span class="docEmphasis">same</span> work with <span class="docEmphasis">less</span> effort, such as by reusing previously computed results through caching or replacing an <span class="docEmphasis">O</span>(<span class="docEmphasis">n</span><sup class="calibre49">2</sup>) algorithm with an <span class="docEmphasis">O</span>(<span class="docEmphasis">n</span> log <span class="docEmphasis">n</span>) one. When tuning for scalability, you are instead trying to find ways to parallelize the problem so you can take advantage of additional processing resources to do <span class="docEmphasis">more</span> work with <span class="docEmphasis">more</span> resources.</p>
<p class="docText1">These two aspects of performance<span class="docEmphasis">how fast</span> and <span class="docEmphasis">how much</span>are completely separate, and sometimes even at odds with each other. In order to achieve higher scalability or better hardware utilization, we often end up <span class="docEmphasis">increasing</span> the amount of work done to process each <span class="docEmphasis">individual</span> task, such as when we divide tasks into multiple "pipelined" subtasks. Ironically, many of the tricks that improve performance in single-threaded programs are bad for scalability (see <a class="calibre2" href="ch11lev1sec4.html#ch11lev2sec11">Section 11.4.4</a> for an example).</p>
<p class="docText1"><a name="iddle1695" class="calibre18" id="iddle1695"></a><a name="iddle1696" class="calibre18" id="iddle1696"></a><a name="iddle1918" class="calibre18" id="iddle1918"></a><a name="iddle1919" class="calibre18" id="iddle1919"></a><a name="iddle2058" class="calibre18" id="iddle2058"></a><a name="iddle2562" class="calibre18" id="iddle2562"></a><a name="iddle2667" class="calibre18" id="iddle2667"></a><a name="iddle2943" class="calibre18" id="iddle2943"></a><a name="iddle2944" class="calibre18" id="iddle2944"></a><a name="iddle2945" class="calibre18" id="iddle2945"></a><a name="iddle3236" class="calibre18" id="iddle3236"></a><a name="iddle3237" class="calibre18" id="iddle3237"></a><a name="iddle3391" class="calibre18" id="iddle3391"></a><a name="iddle3525" class="calibre18" id="iddle3525"></a><a name="iddle3546" class="calibre18" id="iddle3546"></a><a name="iddle3547" class="calibre18" id="iddle3547"></a><a name="iddle3884" class="calibre18" id="iddle3884"></a><a name="iddle3885" class="calibre18" id="iddle3885"></a><a name="iddle4048" class="calibre18" id="iddle4048"></a><a name="iddle4049" class="calibre18" id="iddle4049"></a><a name="iddle4077" class="calibre18" id="iddle4077"></a>The familiar three-tier application modelin which presentation, business logic, and persistence are separated and may be handled by different systemsillustrates how improvements in scalability often come at the expense of performance. A monolithic application where presentation, business logic, and persistence are intertwined would almost certainly provide better performance for the <span class="docEmphasis">first</span> unit of work than would a well-factored multitier implementation distributed over multiple systems. How could it not? The monolithic application would not have the network latency inherent in handing off tasks between tiers, nor would it have to pay the costs inherent in separating a computational process into distinct abstracted layers (such as queuing overhead, coordination overhead, and data copying).</p>
<p class="docText1">However, when the monolithic system reaches its processing capacity, we could have a serious problem: it may be prohibitively difficult to significantly increase capacity. So we often accept the performance costs of longer service time or greater computing resources used per unit of work so that our application can scale to handle greater load by adding more resources.</p>
<p class="docText1">Of the various aspects of performance, the "how much" aspectsscalability, throughput, and capacityare usually of greater concern for server applications than the "how fast" aspects. (For interactive applications, latency tends to be more important, so that users need not wait for indications of progress and wonder what is going on.) This chapter focuses primarily on scalability rather than raw single-threaded performance.</p>
<a name="ch11lev2sec2" class="calibre18" id="ch11lev2sec2"></a>
<h4 id="title-IDAPWCJU" class="docSection2Title">11.1.2. Evaluating Performance Tradeoffs</h4>
<p class="docText1">Nearly all engineering decisions involve some form of tradeoff. Using thicker steel in a bridge span may increase its capacity and safety, but also its construction cost. While software engineering decisions don't usually involve tradeoffs between money and risk to human life, we often have less information with which to make the right tradeoffs. For example, the "quicksort" algorithm is highly efficient for large data sets, but the less sophisticated "bubble sort" is actually more efficient for small data sets. If you are asked to implement an efficient sort routine, you need to know something about the sizes of data sets it will have to process, along with metrics that tell you whether you are trying to optimize average-case time, worst-case time, or predictability. Unfortunately, that information is often not part of the requirements given to the author of a library sort routine. This is one of the reasons why most optimizations are premature: <span class="docEmphasis">they are often undertaken before a clear set of requirements is available</span>.</p>
<a name="ch11sb02" class="calibre18" id="ch11sb02"></a><p class="calibre21"><table cellspacing="0" width="90%" border="1" cellpadding="5" class="calibre5"><tr class="calibre6"><td class="calibre28">
<p class="docText1">Avoid premature optimization. First make it right, then make it fast<span class="docEmphasis">if</span> it is not already fast enough.</p>
</td></tr></table></p><p class="calibre1"> </p>
<p class="docText1">When making engineering decisions, sometimes you are trading one form of cost for another (service time versus memory consumption); sometimes you are trading cost for safety. Safety doesn't necessarily mean risk to human lives, as <a name="iddle1083" class="calibre18" id="iddle1083"></a><a name="iddle1084" class="calibre18" id="iddle1084"></a><a name="iddle1085" class="calibre18" id="iddle1085"></a><a name="iddle1177" class="calibre18" id="iddle1177"></a><a name="iddle1200" class="calibre18" id="iddle1200"></a><a name="iddle1462" class="calibre18" id="iddle1462"></a><a name="iddle1463" class="calibre18" id="iddle1463"></a><a name="iddle1687" class="calibre18" id="iddle1687"></a><a name="iddle1688" class="calibre18" id="iddle1688"></a><a name="iddle1689" class="calibre18" id="iddle1689"></a><a name="iddle1690" class="calibre18" id="iddle1690"></a><a name="iddle1691" class="calibre18" id="iddle1691"></a><a name="iddle1823" class="calibre18" id="iddle1823"></a><a name="iddle1824" class="calibre18" id="iddle1824"></a><a name="iddle1825" class="calibre18" id="iddle1825"></a><a name="iddle1826" class="calibre18" id="iddle1826"></a><a name="iddle1827" class="calibre18" id="iddle1827"></a><a name="iddle1829" class="calibre18" id="iddle1829"></a><a name="iddle1830" class="calibre18" id="iddle1830"></a><a name="iddle1891" class="calibre18" id="iddle1891"></a><a name="iddle1892" class="calibre18" id="iddle1892"></a><a name="iddle1893" class="calibre18" id="iddle1893"></a><a name="iddle1894" class="calibre18" id="iddle1894"></a><a name="iddle1895" class="calibre18" id="iddle1895"></a><a name="iddle1954" class="calibre18" id="iddle1954"></a><a name="iddle1955" class="calibre18" id="iddle1955"></a><a name="iddle1956" class="calibre18" id="iddle1956"></a><a name="iddle1957" class="calibre18" id="iddle1957"></a><a name="iddle1958" class="calibre18" id="iddle1958"></a><a name="iddle2055" class="calibre18" id="iddle2055"></a><a name="iddle2056" class="calibre18" id="iddle2056"></a><a name="iddle2057" class="calibre18" id="iddle2057"></a><a name="iddle2362" class="calibre18" id="iddle2362"></a><a name="iddle2385" class="calibre18" id="iddle2385"></a><a name="iddle2386" class="calibre18" id="iddle2386"></a><a name="iddle2387" class="calibre18" id="iddle2387"></a><a name="iddle2388" class="calibre18" id="iddle2388"></a><a name="iddle2389" class="calibre18" id="iddle2389"></a><a name="iddle2390" class="calibre18" id="iddle2390"></a><a name="iddle2450" class="calibre18" id="iddle2450"></a><a name="iddle2451" class="calibre18" id="iddle2451"></a><a name="iddle2452" class="calibre18" id="iddle2452"></a><a name="iddle2453" class="calibre18" id="iddle2453"></a><a name="iddle2454" class="calibre18" id="iddle2454"></a><a name="iddle2455" class="calibre18" id="iddle2455"></a><a name="iddle2498" class="calibre18" id="iddle2498"></a><a name="iddle2499" class="calibre18" id="iddle2499"></a><a name="iddle2500" class="calibre18" id="iddle2500"></a><a name="iddle2501" class="calibre18" id="iddle2501"></a><a name="iddle2553" class="calibre18" id="iddle2553"></a><a name="iddle2554" class="calibre18" id="iddle2554"></a><a name="iddle2564" class="calibre18" id="iddle2564"></a><a name="iddle2565" class="calibre18" id="iddle2565"></a><a name="iddle2630" class="calibre18" id="iddle2630"></a><a name="iddle2671" class="calibre18" id="iddle2671"></a><a name="iddle2750" class="calibre18" id="iddle2750"></a><a name="iddle2751" class="calibre18" id="iddle2751"></a><a name="iddle2752" class="calibre18" id="iddle2752"></a><a name="iddle2753" class="calibre18" id="iddle2753"></a><a name="iddle2754" class="calibre18" id="iddle2754"></a><a name="iddle2755" class="calibre18" id="iddle2755"></a><a name="iddle2867" class="calibre18" id="iddle2867"></a><a name="iddle2868" class="calibre18" id="iddle2868"></a><a name="iddle3166" class="calibre18" id="iddle3166"></a><a name="iddle3183" class="calibre18" id="iddle3183"></a><a name="iddle3184" class="calibre18" id="iddle3184"></a><a name="iddle3193" class="calibre18" id="iddle3193"></a><a name="iddle3246" class="calibre18" id="iddle3246"></a><a name="iddle3247" class="calibre18" id="iddle3247"></a><a name="iddle3248" class="calibre18" id="iddle3248"></a><a name="iddle3249" class="calibre18" id="iddle3249"></a><a name="iddle3250" class="calibre18" id="iddle3250"></a><a name="iddle3344" class="calibre18" id="iddle3344"></a><a name="iddle3392" class="calibre18" id="iddle3392"></a><a name="iddle3469" class="calibre18" id="iddle3469"></a><a name="iddle3470" class="calibre18" id="iddle3470"></a><a name="iddle3567" class="calibre18" id="iddle3567"></a><a name="iddle3568" class="calibre18" id="iddle3568"></a><a name="iddle3569" class="calibre18" id="iddle3569"></a><a name="iddle3570" class="calibre18" id="iddle3570"></a><a name="iddle3571" class="calibre18" id="iddle3571"></a><a name="iddle3606" class="calibre18" id="iddle3606"></a><a name="iddle3690" class="calibre18" id="iddle3690"></a><a name="iddle3703" class="calibre18" id="iddle3703"></a><a name="iddle3704" class="calibre18" id="iddle3704"></a><a name="iddle3705" class="calibre18" id="iddle3705"></a><a name="iddle3742" class="calibre18" id="iddle3742"></a><a name="iddle3880" class="calibre18" id="iddle3880"></a><a name="iddle3881" class="calibre18" id="iddle3881"></a><a name="iddle3898" class="calibre18" id="iddle3898"></a><a name="iddle3899" class="calibre18" id="iddle3899"></a><a name="iddle3900" class="calibre18" id="iddle3900"></a><a name="iddle3901" class="calibre18" id="iddle3901"></a><a name="iddle3902" class="calibre18" id="iddle3902"></a><a name="iddle3903" class="calibre18" id="iddle3903"></a><a name="iddle3916" class="calibre18" id="iddle3916"></a><a name="iddle3917" class="calibre18" id="iddle3917"></a><a name="iddle3918" class="calibre18" id="iddle3918"></a><a name="iddle4005" class="calibre18" id="iddle4005"></a><a name="iddle4006" class="calibre18" id="iddle4006"></a><a name="iddle4010" class="calibre18" id="iddle4010"></a><a name="iddle4011" class="calibre18" id="iddle4011"></a><a name="iddle4012" class="calibre18" id="iddle4012"></a><a name="iddle4120" class="calibre18" id="iddle4120"></a><a name="iddle4121" class="calibre18" id="iddle4121"></a><a name="iddle4282" class="calibre18" id="iddle4282"></a><a name="iddle4337" class="calibre18" id="iddle4337"></a><a name="iddle4442" class="calibre18" id="iddle4442"></a><a name="iddle4451" class="calibre18" id="iddle4451"></a><a name="iddle4452" class="calibre18" id="iddle4452"></a><a name="iddle4453" class="calibre18" id="iddle4453"></a><a name="iddle4454" class="calibre18" id="iddle4454"></a><a name="iddle4455" class="calibre18" id="iddle4455"></a><a name="iddle4667" class="calibre18" id="iddle4667"></a><a name="iddle4668" class="calibre18" id="iddle4668"></a><a name="iddle4669" class="calibre18" id="iddle4669"></a><a name="iddle4687" class="calibre18" id="iddle4687"></a><a name="iddle4688" class="calibre18" id="iddle4688"></a><a name="iddle4689" class="calibre18" id="iddle4689"></a><a name="iddle4690" class="calibre18" id="iddle4690"></a><a name="iddle4691" class="calibre18" id="iddle4691"></a><a name="iddle4692" class="calibre18" id="iddle4692"></a><a name="iddle4937" class="calibre18" id="iddle4937"></a><a name="iddle4938" class="calibre18" id="iddle4938"></a><a name="iddle4945" class="calibre18" id="iddle4945"></a><a name="iddle5109" class="calibre18" id="iddle5109"></a><a name="iddle5110" class="calibre18" id="iddle5110"></a>it did in the bridge example. Many performance optimizations come at the cost of readability or maintainabilitythe more "clever" or nonobvious code is, the harder it is to understand and maintain. Sometimes optimizations entail compromising good object-oriented design principles, such as breaking encapsulation; sometimes they involve greater risk of error, because faster algorithms are usually more complicated. (If you can't spot the costs or risks, you probably haven't thought it through carefully enough to proceed.)</p>
<p class="docText1">Most performance decisions involve multiple variables and are highly situational. Before deciding that one approach is "faster" than another, ask yourself some questions:</p>
<ul class="calibre15"><li class="calibre16"><p class="docText1">What do you mean by "faster"?</p></li><li class="calibre16"><p class="docText1">Under what conditions will this approach <span class="docEmphasis">actually</span> be faster? Under light or heavy load? With large or small data sets? Can you support your answer with measurements?</p></li><li class="calibre16"><p class="docText1">How often are these conditions likely to arise in your situation? Can you support your answer with measurements?</p></li><li class="calibre16"><p class="docText1">Is this code likely to be used in other situations where the conditions may be different?</p></li><li class="calibre16"><p class="docText1">What hidden costs, such as increased development or maintenance risk, are you trading for this improved performance? Is this a good tradeoff?</p></li></ul>
<p class="docText1">These considerations apply to any performance-related engineering decision, but this is a book about concurrency. Why are we recommending such a conservative approach to optimization? <span class="docEmphasis">The quest for performance is probably the single greatest source of concurrency bugs.</span> The belief that synchronization was "too slow" led to many clever-looking but dangerous idioms for reducing synchronization (such as double-checked locking, discussed in <a class="calibre2" href="ch16lev1sec2.html#ch16lev2sec8">Section 16.2.4</a>), and is often cited as an excuse for not following the rules regarding synchronization. Because concurrency bugs are among the most difficult to track down and eliminate, however, anything that risks introducing them must be undertaken very carefully.</p>
<p class="docText1">Worse, when you trade safety for performance, you may get neither. Especially when it comes to concurrency, the intuition of many developers about where a performance problem lies or which approach will be faster or more scalable is often incorrect. It is therefore imperative that any performance tuning exercise be accompanied by concrete performance requirements (so you know both when to tune and when to <span class="docEmphasis">stop</span> tuning) and with a measurement program in place using a realistic configuration and load profile. Measure again after tuning to verify that you've achieved the desired improvements. The safety and maintenance risks associated with many optimizations are bad enoughyou don't want to pay these costs if you don't need toand you definitely don't want to pay them if you don't even get the desired benefit.</p>
<a name="ch11sb03" class="calibre18" id="ch11sb03"></a><p class="calibre21"><table cellspacing="0" width="90%" border="1" cellpadding="5" class="calibre5"><tr class="calibre6"><td class="calibre28">
<p class="docText1">Measure, don't guess.</p>
</td></tr></table></p><p class="calibre1"> </p>
<p class="docText1"><a name="iddle1077" class="calibre18" id="iddle1077"></a><a name="iddle1078" class="calibre18" id="iddle1078"></a><a name="iddle1079" class="calibre18" id="iddle1079"></a><a name="iddle1080" class="calibre18" id="iddle1080"></a><a name="iddle3186" class="calibre18" id="iddle3186"></a><a name="iddle3189" class="calibre18" id="iddle3189"></a><a name="iddle3190" class="calibre18" id="iddle3190"></a><a name="iddle3389" class="calibre18" id="iddle3389"></a><a name="iddle3390" class="calibre18" id="iddle3390"></a><a name="iddle3456" class="calibre18" id="iddle3456"></a><a name="iddle3457" class="calibre18" id="iddle3457"></a><a name="iddle3472" class="calibre18" id="iddle3472"></a><a name="iddle3513" class="calibre18" id="iddle3513"></a><a name="iddle3694" class="calibre18" id="iddle3694"></a><a name="iddle3939" class="calibre18" id="iddle3939"></a><a name="iddle3940" class="calibre18" id="iddle3940"></a><a name="iddle4180" class="calibre18" id="iddle4180"></a><a name="iddle4181" class="calibre18" id="iddle4181"></a><a name="iddle4185" class="calibre18" id="iddle4185"></a><a name="iddle4186" class="calibre18" id="iddle4186"></a><a name="iddle4652" class="calibre18" id="iddle4652"></a><a name="iddle4653" class="calibre18" id="iddle4653"></a><a name="iddle4951" class="calibre18" id="iddle4951"></a><a name="iddle5030" class="calibre18" id="iddle5030"></a><a name="iddle5031" class="calibre18" id="iddle5031"></a><a name="iddle5032" class="calibre18" id="iddle5032"></a><a name="iddle5033" class="calibre18" id="iddle5033"></a>There are sophisticated profiling tools on the market for measuring performance and tracking down performance bottlenecks, but you don't have to spend a lot of money to figure out what your program is doing. For example, the free <tt class="calibre25">perfbar</tt> application can give you a good picture of how busy the CPUs are, and since your goal is usually to keep the CPUs busy, this is a very good way to evaluate whether you need performance tuning or how effective your tuning has been.</p>

<p class="calibre1"> </p>

</div>

{% endraw %}

