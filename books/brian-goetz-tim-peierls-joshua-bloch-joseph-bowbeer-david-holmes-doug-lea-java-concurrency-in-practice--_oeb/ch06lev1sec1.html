---
layout: page
title: "Java Concurrency in Practice"
prev: ch06.html
next: ch06lev1sec2.html
book_path: books/brian-goetz-tim-peierls-joshua-bloch-joseph-bowbeer-david-holmes-doug-lea-java-concurrency-in-practice--_oeb/
---
{% include JB/setup %}
{% raw %}
<div>


<a name="ch06lev1sec1" class="calibre18" id="ch06lev1sec1"></a>
<h3 id="631532-873" class="docSection1Title">6.1. Executing Tasks in Threads</h3>
<p class="docText1">The first step in organizing a program around task execution is identifying sensible <span class="docEmphasis">task boundaries</span>. Ideally, tasks are <span class="docEmphasis">independent</span> activities: work that doesn't depend on the state, result, or side effects of other tasks. Independence facilitates concurrency, as independent tasks can be executed in parallel if there are adequate processing resources. For greater flexibility in scheduling and load balancing tasks, each task should also represent a small fraction of your application's processing capacity.</p>
<p class="docText1">Server applications should exhibit both <span class="docEmphasis">good throughput</span> and <span class="docEmphasis">good responsiveness</span> under normal load. Application providers want applications to support as many users as possible, so as to reduce provisioning costs per user; users want to get their response quickly. Further, applications should exhibit <span class="docEmphasis">graceful degradation</span> as they become overloaded, rather than simply falling over under heavy load. Choosing good task boundaries, coupled with a sensible <span class="docEmphasis">task execution policy</span> (see <a class="calibre2" href="ch06lev1sec2.html#ch06lev2sec5">Section 6.2.2</a>), can help achieve these goals.</p>
<p class="docText1">Most server applications offer a natural choice of task boundary: individual client requests. Web servers, mail servers, file servers, EJB containers, and database servers all accept requests via network connections from remote clients. Using individual requests as task boundaries usually offers both independence and appropriate task sizing. For example, the result of submitting a message to a mail server is not affected by the other messages being processed at the same time, and handling a single message usually requires a very small percentage of the server's total capacity.</p>
<a name="ch06lev2sec1" class="calibre18" id="ch06lev2sec1"></a>
<h4 id="title-IDAMJRDD" class="docSection2Title">6.1.1. Executing Tasks Sequentially</h4>
<p class="docText1"><a name="iddle2180" class="calibre18" id="iddle2180"></a><a name="iddle2251" class="calibre18" id="iddle2251"></a><a name="iddle2488" class="calibre18" id="iddle2488"></a><a name="iddle2489" class="calibre18" id="iddle2489"></a><a name="iddle2679" class="calibre18" id="iddle2679"></a><a name="iddle2680" class="calibre18" id="iddle2680"></a><a name="iddle3589" class="calibre18" id="iddle3589"></a><a name="iddle3590" class="calibre18" id="iddle3590"></a><a name="iddle3596" class="calibre18" id="iddle3596"></a><a name="iddle3597" class="calibre18" id="iddle3597"></a><a name="iddle3926" class="calibre18" id="iddle3926"></a><a name="iddle3969" class="calibre18" id="iddle3969"></a><a name="iddle4096" class="calibre18" id="iddle4096"></a><a name="iddle4097" class="calibre18" id="iddle4097"></a><a name="iddle4163" class="calibre18" id="iddle4163"></a><a name="iddle4164" class="calibre18" id="iddle4164"></a><a name="iddle4169" class="calibre18" id="iddle4169"></a><a name="iddle4301" class="calibre18" id="iddle4301"></a><a name="iddle4302" class="calibre18" id="iddle4302"></a><a name="iddle4623" class="calibre18" id="iddle4623"></a><a name="iddle4820" class="calibre18" id="iddle4820"></a><a name="iddle4821" class="calibre18" id="iddle4821"></a><a name="iddle4876" class="calibre18" id="iddle4876"></a><a name="iddle4877" class="calibre18" id="iddle4877"></a>There are a number of possible policies for scheduling tasks within an application, some of which exploit the potential for concurrency better than others. The simplest is to execute tasks sequentially in a single thread. <tt class="calibre25">SingleThreadWeb-Server</tt> in <a class="calibre2" href="#ch06list01">Listing 6.1</a> processes its tasksHTTP requests arriving on port 80sequentially. The details of the request processing aren't important; we're interested in characterizing the concurrency of various scheduling policies.</p>
<a name="ch06list01" class="calibre18" id="ch06list01"></a><h5 id="title-IDAQ0RDD" class="docExampleTitle">Listing 6.1. Sequential Web Server.</h5><p class="calibre21"><table cellspacing="0" width="90%" border="1" cellpadding="5" class="calibre5"><tr class="calibre6"><td class="calibre28">
<img border="0" alt="" id="195131084199" src="face1.jpg" class="calibre31"/>
<pre class="calibre30">class SingleThreadWebServer {
    public static void main(String[] args) throws IOException {
        ServerSocket socket = new ServerSocket(80);
        while (true) {
            Socket connection = socket.accept();
            handleRequest(connection);
        }
    }
}
</pre><br class="calibre11"/>
</td></tr></table></p>
<p class="docText1"><tt class="calibre25">SingleThreadedWebServer</tt> is simple and theoretically correct, but would perform poorly in production because it can handle only one request at a time. The main thread alternates between accepting connections and processing the associated request. While the server is handling a request, new connections must wait until it finishes the current request and calls <tt class="calibre25">accept</tt> again. This might work if request processing were so fast that <tt class="calibre25">handleRequest</tt> effectively returned immediately, but this doesn't describe any web server in the real world.</p>
<p class="docText1">Processing a web request involves a mix of computation and I/O. The server must perform socket I/O to read the request and write the response, which can block due to network congestion or connectivity problems. It may also perform file I/O or make database requests, which can also block. In a single-threaded server, blocking not only delays completing the current request, but prevents pending requests from being processed at all. If one request blocks for an unusually long time, users might think the server is unavailable because it appears unresponsive. At the same time, resource utilization is poor, since the CPU sits idle while the single thread waits for its I/O to complete.</p>
<p class="docText1">In server applications, sequential processing rarely provides either good throughput or good responsiveness. There are exceptionssuch as when tasks are few and long-lived, or when the server serves a single client that makes only a single request at a timebut most server applications do not work this way.<sup class="docFootnote"><a class="calibre2" href="#ch06fn01">[1]</a></sup></p><blockquote class="calibre19"><p class="docFootnote1"><sup class="calibre27"><a name="ch06fn01" class="calibre18" id="ch06fn01">[1]</a></sup> In some situations, sequential processing may offer a simplicity or safety advantage; most GUI frameworks process tasks sequentially using a single thread. We return to the sequential model in <a class="calibre2" href="ch09.html#ch09">Chapter 9</a>.</p></blockquote>
<a name="ch06lev2sec2" class="calibre18" id="ch06lev2sec2"></a>
<h4 id="title-IDAG2RDD" class="docSection2Title">6.1.2. Explicitly Creating Threads for Tasks</h4>
<p class="docText1"><a name="iddle1730" class="calibre18" id="iddle1730"></a><a name="iddle2203" class="calibre18" id="iddle2203"></a><a name="iddle3459" class="calibre18" id="iddle3459"></a><a name="iddle3600" class="calibre18" id="iddle3600"></a><a name="iddle4098" class="calibre18" id="iddle4098"></a><a name="iddle4624" class="calibre18" id="iddle4624"></a><a name="iddle4650" class="calibre18" id="iddle4650"></a><a name="iddle4651" class="calibre18" id="iddle4651"></a><a name="iddle4764" class="calibre18" id="iddle4764"></a><a name="iddle4831" class="calibre18" id="iddle4831"></a>A more responsive approach is to create a new thread for servicing each request, as shown in <tt class="calibre25">ThreadPerTaskWebServer</tt> in <a class="calibre2" href="#ch06list02">Listing 6.2</a>.</p>
<a name="ch06list02" class="calibre18" id="ch06list02"></a><h5 id="title-IDAQISDD" class="docExampleTitle">Listing 6.2. Web Server that Starts a New Thread for Each Request.</h5><p class="calibre21"><table cellspacing="0" width="90%" border="1" cellpadding="5" class="calibre5"><tr class="calibre6"><td class="calibre28">
<img border="0" alt="" id="195131084199" src="face1.jpg" class="calibre31"/>
<pre class="calibre30">class ThreadPerTaskWebServer {
    public static void main(String[] args) throws IOException {
        ServerSocket socket = new ServerSocket(80);
        while (true) {
            <span class="docEmphStrong">final</span>  Socket connection = socket.accept();
            Runnable task = new Runnable() {
                    public void run() {
                        <span class="docEmphStrong">handleRequest(connection);</span>
                    }
                };
            <span class="docEmphStrong">new Thread(task).start();</span>
        }
    }
}
</pre><br class="calibre11"/>
</td></tr></table></p>
<p class="docText1"><tt class="calibre25">THReadPerTaskWebServer</tt> is similar in structure to the single-threaded versionthe main thread still alternates between accepting an incoming connection and dispatching the request. The difference is that for each connection, the main loop creates a new thread to process the request instead of processing it within the main thread. This has three main consequences:</p>
<ul class="calibre15"><li class="calibre16"><p class="docText1">Task processing is offloaded from the main thread, enabling the main loop to resume waiting for the next incoming connection more quickly. This enables new connections to be accepted before previous requests complete, improving responsiveness.</p></li><li class="calibre16"><p class="docText1">Tasks can be processed in parallel, enabling multiple requests to be serviced simultaneously. This may improve throughput if there are multiple processors, or if tasks need to block for any reason such as I/O completion, lock acquisition, or resource availability.</p></li><li class="calibre16"><p class="docText1">Task-handling code must be thread-safe, because it may be invoked concurrently for multiple tasks.</p></li></ul>
<p class="docText1">Under light to moderate load, the thread-per-task approach is an improvement over sequential execution. As long as the request arrival rate does not exceed the server's capacity to handle requests, this approach offers better responsiveness and throughput.</p>
<a name="ch06lev2sec3" class="calibre18" id="ch06lev2sec3"></a>
<h4 id="title-IDANKSDD" class="docSection2Title">6.1.3. Disadvantages of Unbounded Thread Creation</h4>
<p class="docText1"><a name="iddle1125" class="calibre18" id="iddle1125"></a><a name="iddle1126" class="calibre18" id="iddle1126"></a><a name="iddle1563" class="calibre18" id="iddle1563"></a><a name="iddle1564" class="calibre18" id="iddle1564"></a><a name="iddle1732" class="calibre18" id="iddle1732"></a><a name="iddle1765" class="calibre18" id="iddle1765"></a><a name="iddle1766" class="calibre18" id="iddle1766"></a><a name="iddle1767" class="calibre18" id="iddle1767"></a><a name="iddle1768" class="calibre18" id="iddle1768"></a><a name="iddle1769" class="calibre18" id="iddle1769"></a><a name="iddle1836" class="calibre18" id="iddle1836"></a><a name="iddle2981" class="calibre18" id="iddle2981"></a><a name="iddle2982" class="calibre18" id="iddle2982"></a><a name="iddle3199" class="calibre18" id="iddle3199"></a><a name="iddle3420" class="calibre18" id="iddle3420"></a><a name="iddle3421" class="calibre18" id="iddle3421"></a><a name="iddle3491" class="calibre18" id="iddle3491"></a><a name="iddle3492" class="calibre18" id="iddle3492"></a><a name="iddle3749" class="calibre18" id="iddle3749"></a><a name="iddle3910" class="calibre18" id="iddle3910"></a><a name="iddle3911" class="calibre18" id="iddle3911"></a><a name="iddle3931" class="calibre18" id="iddle3931"></a><a name="iddle4353" class="calibre18" id="iddle4353"></a><a name="iddle4354" class="calibre18" id="iddle4354"></a><a name="iddle4355" class="calibre18" id="iddle4355"></a><a name="iddle4765" class="calibre18" id="iddle4765"></a><a name="iddle47861" class="calibre18" id="iddle47861"></a><a name="iddle4786" class="calibre18" id="iddle4786"></a><a name="iddle4787" class="calibre18" id="iddle4787"></a><a name="iddle4832" class="calibre18" id="iddle4832"></a><a name="iddle4838" class="calibre18" id="iddle4838"></a><a name="iddle4997" class="calibre18" id="iddle4997"></a><a name="iddle4998" class="calibre18" id="iddle4998"></a><a name="iddle5154" class="calibre18" id="iddle5154"></a>For production use, however, the thread-per-task approach has some practical drawbacks, especially when a large number of threads may be created:</p>
<p class="docText1"><span class="docEmphStrong">Thread lifecycle overhead.</span> Thread creation and teardown are not free. The actual overhead varies across platforms, but thread creation takes time, introducing latency into request processing, and requires some processing activity by the JVM and OS. If requests are frequent and lightweight, as in most server applications, creating a new thread for each request can consume significant computing resources.</p>
<p class="docText1"><span class="docEmphStrong">Resource consumption.</span> Active threads consume system resources, especially memory. When there are more runnable threads than available processors, threads sit idle. Having many idle threads can tie up a lot of memory, putting pressure on the garbage collector, and having many threads competing for the CPUs can impose other performance costs as well. If you have enough threads to keep all the CPUs busy, creating more threads won't help and may even hurt.</p>
<p class="docText1"><span class="docEmphStrong">Stability.</span> There is a limit on how many threads can be created. The limit varies by platform and is affected by factors including JVM invocation parameters, the requested stack size in the <tt class="calibre25">Thread</tt> constructor, and limits on threads placed by the underlying operating system.<sup class="docFootnote"><a class="calibre2" href="#ch06fn02">[2]</a></sup> When you hit this limit, the most likely result is an <tt class="calibre25">OutOfMemoryError</tt>. trying to recover from such an error is very risky; it is far easier to structure your program to avoid hitting this limit.<blockquote class="calibre19"><p class="docFootnote2"><sup class="calibre27"><a name="ch06fn02" class="calibre18" id="ch06fn02">[2]</a></sup> On 32-bit machines, a major limiting factor is address space for thread stacks. Each thread maintains two execution stacks, one for Java code and one for native code. Typical JVM defaults yield a combined stack size of around half a megabyte. (You can change this with the <tt class="calibre35">-Xss</tt> JVM flag or through the <tt class="calibre35">Thread</tt> constructor.) If you divide the per-thread stack size into 2<sup class="calibre27">32</sup>, you get a limit of a few thousands or tens of thousands of threads. Other factors, such as OS limitations, may impose stricter limits.</p></blockquote></p>
<p class="docText1">Up to a certain point, more threads can improve throughput, but beyond that point creating more threads just slows down your application, and creating one thread too many can cause your entire application to crash horribly. The way to stay out of danger is to place some bound on how many threads your application creates, and to test your application thoroughly to ensure that, even when this bound is reached, it does not run out of resources.</p>
<p class="docText1">The problem with the thread-per-task approach is that nothing places any limit on the number of threads created except the rate at which remote users can throw HTTP requests at it. Like other concurrency hazards, unbounded thread creation may <span class="docEmphasis">appear</span> to work just fine during prototyping and development, with problems surfacing only when the application is deployed and under heavy load. So a malicious user, or enough ordinary users, can make your web server crash if the traffic load ever reaches a certain threshold. For a server application that is supposed to provide high availability and graceful degradation under load, this is a serious failing.</p>

<p class="calibre1">Â </p>

</div>

{% endraw %}

