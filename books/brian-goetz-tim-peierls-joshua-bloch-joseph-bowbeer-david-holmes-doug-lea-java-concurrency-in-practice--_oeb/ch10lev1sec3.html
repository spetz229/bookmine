---
layout: page
title: "Java Concurrency in Practice"
prev: ch10lev1sec2.html
next: ch10lev1sec4.html
book_path: books/brian-goetz-tim-peierls-joshua-bloch-joseph-bowbeer-david-holmes-doug-lea-java-concurrency-in-practice--_oeb/
---
{% include JB/setup %}
{% raw %}
<div>


<a name="ch10lev1sec3" class="calibre18" id="ch10lev1sec3"></a>
<h3 id="title-IDACIE2V" class="docSection1Title">10.3. Other Liveness Hazards</h3>
<p class="docText1"><a name="iddle1649" class="calibre18" id="iddle1649"></a><a name="iddle2330" class="calibre18" id="iddle2330"></a><a name="iddle2331" class="calibre18" id="iddle2331"></a><a name="iddle2585" class="calibre18" id="iddle2585"></a><a name="iddle2586" class="calibre18" id="iddle2586"></a><a name="iddle2889" class="calibre18" id="iddle2889"></a><a name="iddle3660" class="calibre18" id="iddle3660"></a><a name="iddle3661" class="calibre18" id="iddle3661"></a><a name="iddle4095" class="calibre18" id="iddle4095"></a><a name="iddle4131" class="calibre18" id="iddle4131"></a><a name="iddle4132" class="calibre18" id="iddle4132"></a><a name="iddle4367" class="calibre18" id="iddle4367"></a><a name="iddle4368" class="calibre18" id="iddle4368"></a><a name="iddle4369" class="calibre18" id="iddle4369"></a><a name="iddle4370" class="calibre18" id="iddle4370"></a><a name="iddle4371" class="calibre18" id="iddle4371"></a><a name="iddle4806" class="calibre18" id="iddle4806"></a><a name="iddle4807" class="calibre18" id="iddle4807"></a>While deadlock is the most widely encountered liveness hazard, there are several other liveness hazards you may encounter in concurrent programs including starvation, missed signals, and livelock. (Missed signals are covered in <a class="calibre2" href="ch14lev1sec2.html#ch14lev2sec4">Section 14.2.3</a>.)</p>
<a name="ch10lev2sec8" class="calibre18" id="ch10lev2sec8"></a>
<h4 id="title-IDAVPE2V" class="docSection2Title">10.3.1. Starvation</h4>
<p class="docText1"><span class="docEmphasis">Starvation</span> occurs when a thread is perpetually denied access to resources it needs in order to make progress; the most commonly starved resource is CPU cycles. Starvation in Java applications can be caused by inappropriate use of thread priorities. It can also be caused by executing nonterminating constructs (infinite loops or resource waits that do not terminate) with a lock held, since other threads that need that lock will never be able to acquire it.</p>
<p class="docText1">The thread priorities defined in the Thread API are merely scheduling hints. The Thread API defines ten priority levels that the JVM can map to operating system scheduling priorities as it sees fit. This mapping is platform-specific, so two Java priorities can map to the same OS priority on one system and different OS priorities on another. Some operating systems have fewer than ten priority levels, in which case multiple Java priorities map to the same OS priority.</p>
<p class="docText1">Operating system schedulers go to great lengths to provide scheduling fairness and liveness beyond that required by the Java Language Specification. In most Java applications, all application threads have the same priority, <tt class="calibre25">Thread. NORM_PRIORITY</tt>. The thread priority mechanism is a blunt instrument, and it's not always obvious what effect changing priorities will have; boosting a thread's priority might do nothing or might always cause one thread to be scheduled in preference to the other, causing starvation.</p>
<p class="docText1">It is generally wise to resist the temptation to tweak thread priorities. As soon as you start modifying priorities, the behavior of your application becomes platform-specific and you introduce the risk of starvation. You can often spot a program that is trying to recover from priority tweaking or other responsiveness problems by the presence of <tt class="calibre25">Thread.sleep</tt> or <tt class="calibre25">Thread.yield</tt> calls in odd places, in an attempt to give more time to lower-priority threads.<sup class="docFootnote"><a class="calibre2" href="#ch10fn05">[5]</a></sup></p><blockquote class="calibre19"><p class="docFootnote1"><sup class="calibre27"><a name="ch10fn05" class="calibre18" id="ch10fn05">[5]</a></sup> The semantics of <tt class="calibre35">THRead.yield</tt> (and <tt class="calibre35">Thread.sleep(0)</tt>) are undefined [JLS 17.9]; the JVM is free to implement them as no-ops or treat them as scheduling hints. In particular, they are <span class="docEmphasis">not</span> required to have the semantics of <tt class="calibre35">sleep(0)</tt> on Unix systemsput the current thread at the end of the run queue for that priority, yielding to other threads of the same prioritythough some JVMs implement <tt class="calibre35">yield</tt> in this way.</p></blockquote>
<a name="ch10sb04" class="calibre18" id="ch10sb04"></a><p class="calibre21"><table cellspacing="0" width="90%" border="1" cellpadding="5" class="calibre5"><tr class="calibre6"><td class="calibre28">
<p class="docText1">Avoid the temptation to use thread priorities, since they increase platform dependence and can cause liveness problems. Most concurrent applications can use the default priority for all threads.</p>
</td></tr></table></p><p class="calibre1">Â </p>
<a name="ch10lev2sec9" class="calibre18" id="ch10lev2sec9"></a>
<h4 id="title-IDAPRE2V" class="docSection2Title">10.3.2. Poor Responsiveness</h4>
<p class="docText1"><a name="iddle2053" class="calibre18" id="iddle2053"></a><a name="iddle2054" class="calibre18" id="iddle2054"></a><a name="iddle2283" class="calibre18" id="iddle2283"></a><a name="iddle2284" class="calibre18" id="iddle2284"></a><a name="iddle3011" class="calibre18" id="iddle3011"></a><a name="iddle3012" class="calibre18" id="iddle3012"></a><a name="iddle3013" class="calibre18" id="iddle3013"></a><a name="iddle3558" class="calibre18" id="iddle3558"></a><a name="iddle3559" class="calibre18" id="iddle3559"></a><a name="iddle3662" class="calibre18" id="iddle3662"></a><a name="iddle3786" class="calibre18" id="iddle3786"></a><a name="iddle3787" class="calibre18" id="iddle3787"></a><a name="iddle3962" class="calibre18" id="iddle3962"></a><a name="iddle3963" class="calibre18" id="iddle3963"></a><a name="iddle3993" class="calibre18" id="iddle3993"></a><a name="iddle3994" class="calibre18" id="iddle3994"></a><a name="iddle4808" class="calibre18" id="iddle4808"></a><a name="iddle4809" class="calibre18" id="iddle4809"></a>One step removed from starvation is poor responsiveness, which is not uncommon in GUI applications using background threads. <a class="calibre2" href="ch09.html#ch09">Chapter 9</a> developed a framework for offloading long-running tasks onto background threads so as not to freeze the user interface. CPU-intensive background tasks can still affect responsiveness because they can compete for CPU cycles with the event thread. This is one case where altering thread priorities makes sense; when computeintensive background computations would affect responsiveness. If the work done by other threads are truly background tasks, lowering their priority can make the foreground tasks more responsive.</p>
<p class="docText1">Poor responsiveness can also be caused by poor lock management. If a thread holds a lock for a long time (perhaps while iterating a large collection and performing substantial work for each element), other threads that need to access that collection may have to wait a very long time.</p>
<a name="ch10lev2sec10" class="calibre18" id="ch10lev2sec10"></a>
<h4 id="title-IDARYE2V" class="docSection2Title">10.3.3. Livelock</h4>
<p class="docText1"><span class="docEmphasis">Livelock</span> is a form of liveness failure in which a thread, while not blocked, still cannot make progress because it keeps retrying an operation that will always fail. Livelock often occurs in transactional messaging applications, where the messaging infrastructure rolls back a transaction if a message cannot be processed successfully, and puts it back at the head of the queue. If a bug in the message handler for a particular type of message causes it to fail, every time the message is dequeued and passed to the buggy handler, the transaction is rolled back. Since the message is now back at the head of the queue, the handler is called over and over with the same result. (This is sometimes called the <span class="docEmphasis">poison message</span> problem.) The message handling thread is not blocked, but it will never make progress either. This form of livelock often comes from overeager error-recovery code that mistakenly treats an unrecoverable error as a recoverable one.</p>
<p class="docText1">Livelock can also occur when multiple cooperating threads change their state in response to the others in such a way that no thread can ever make progress. This is similar to what happens when two overly polite people are walking in opposite directions in a hallway: each steps out of the other's way, and now they are again in each other's way. So they both step aside again, and again, and again. . .</p>
<p class="docText1">The solution for this variety of livelock is to introduce some randomness into the retry mechanism. For example, when two stations in an ethernet network try to send a packet on the shared carrier at the same time, the packets collide. The stations detect the collision, and each tries to send their packet again later. If they each retry <span class="docEmphasis">exactly</span> one second later, they collide over and over, and neither packet ever goes out, even if there is plenty of available bandwidth. To avoid this, we make each wait an amount of time that includes a random component. (The ethernet protocol also includes exponential backoff after repeated collisions, reducing both congestion and the risk of repeated failure with multiple colliding stations.) Retrying with random waits and backoffs can be equally effective for avoiding livelock in concurrent applications.</p>

<p class="calibre1">Â </p>

</div>

{% endraw %}

