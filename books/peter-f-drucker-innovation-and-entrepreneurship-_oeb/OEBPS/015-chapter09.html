---
layout: page
title: "Innovation and Entrepreneurship"
prev: OEBPS/014-chapter08.html
next: OEBPS/016-chapter10.html
book_path: books/peter-f-drucker-innovation-and-entrepreneurship-_oeb/
---
{% include JB/setup %}
{% raw %}
<div>

<div class="calibre3"></div><div class="frontMatterPage" id="chapter09">
<a id="page115" class="calibre"></a>
<div class="chapterHead">
<h2 class="chapterNumber"><span class="xrefInternal"><a href="003-TOC.html#chapter_09" class="calibre1"><span class="bold">9</span></a></span></h2>
<h2 class="chapterTitle1"><span class="bold">Source: New Knowledge</span></h2></div>
<div class="contents">
<p class="chapterOpenerText">Knowledge-based innovation is the “super-star” of entrepreneurship. It gets the publicity. It gets the money. It is what people normally mean when they talk of innovation. Of course, not all knowledge-based innovations are important. Some are truly trivial. But amongst the history-making innovations, knowledge-based innovations rank high. The knowledge, however, is not necessarily scientific or technical. Social innovations based on knowledge can have equal or even greater impact.</p>
<p class="para">Knowledge-based innovation differs from all other innovations in its basic characteristics: time span, casualty rate, predictability, and in the challenges it poses to the entrepreneur. And like most “superstars,” knowledge-based innovation is temperamental, capricious, and hard to manage.</p>
<p class="chapterHeadA">I</p>
<p class="chapterHeadB"><span class="smallCaps">THE CHARACTERISTICS OF KNOWLEDGE-BASED INNOVATION</span></p>
<p class="para">Knowledge-based innovation has the longest lead time of all innovations. There is, first, a long time span between the emergence of new knowledge and its becoming applicable to technology. And then there is another long period before the new technology turns into products, processes, or services in the marketplace.</p>
<p class="para">Between 1907 and 1910, the biochemist Paul Ehrlich developed the theory of chemotherapy, the control of bacterial microorganisms through chemical compounds. He himself developed the first antibacterial drug, Salvarsan, for the control of syphilis. The sulfa drugs which are the application of Ehrlich’s chemotherapy to the control of a broad <a id="page116" class="calibre"></a>spectrum of bacterial diseases came on the market after 1936, twenty-five years later.</p>
<p class="para">Rudolph Diesel designed the engine which bears his name in 1897. Everyone at once realized that it was a major innovation. Yet for many years there were few practical applications. Then in 1935 an American, Charles Kettering, totally redesigned Diesel’s engine, rendering it capable of being used as the propulsion unit in a wide variety of ships, in locomotives, in trucks, buses, and passenger cars.</p>
<p class="para">A number of knowledges came together to make possible the computer. The earliest was the binary theorem, a mathematical theory going back to the seventeenth century that enables all numbers to be expressed by two numbers only: one and zero. It was applied to a calculating machine by Charles Babbage in the first half of the nineteenth century. In 1890, Hermann Hollerith invented the punchcard, going back to an invention by the early nineteenth-century Frenchman J-M. Jacquard. The punchcard makes it possible to convert numbers into “instructions.” In 1906 an American, Lee de Forest, invented the audion tube, and with it created electronics. Then, between 1910 and 1913, Bertrand Russell and Alfred North Whitehead, in their <span class="italic">Principia Mathematica,</span> created symbolic logic, which enables us to express all logical concepts as numbers. Finally, during World War I, the concepts of programming and feedback were developed, primarily for the purposes of antiaircraft gunnery. By 1918, in other words, all the knowledge needed to develop the computer was available. The first computer became operational in 1946.</p>
<p class="para">A Ford Motor Company manufacturing executive coined the word “automation” in 1951 and described in detail the entire manufacturing process automation would require. “Robotics” and factory automation were widely talked about for twenty-five years, but nothing really happened for a long time. Nissan and Toyota in Japan did not introduce robots into their plants until 1978. In the early eighties, General Electric built an automated locomotive plant in Erie, Pennsylvania. General Motors then began to automate several of its engine and accessory plants. Early in 1985, Volkswagen began to operate its “Hall 54” as an almost completely automated manufacturing installation.</p>
<p class="para">Buckminster Fuller, who called himself a geometer and who was part mathematician and part philosopher, applied the mathematics of topology to the design of what he called the “Dymaxion House,” a term he chose because he liked the sound of it. The Dymaxion House com<a id="page117" class="calibre"></a>bines the greatest possible living space with the smallest possible surface. It therefore has optimal insulation, optimal heating and cooling, and superb acoustics. It also can be built with lightweight materials, requires no foundation and a minimum of suspension, and can still withstand an earthquake or the fiercest gale. Around 1940, Fuller put a Dymaxion House on the campus of a small New England college. And there it stayed. Very few Dymaxion Houses have been built—Americans, it seems, do not like to live in circular homes. But around 1965, Dymaxion structures began to be put up in the Arctic and Antarctic where conventional buildings are impractical, expensive, and difficult to erect. Since then they have increasingly been used for large structures such as auditoriums, concert tents, sports arenas, and so on.</p>
<p class="para">Only major external crises can shorten this lead time. De Forest’s audion tube, invented in 1906, would have made radio possible almost immediately, but it would still not have been on the market until the late 1930s or so had not World War I forced governments, and especially the American government, to push the development of wireless transmission of sounds. Field telephones connected by wires were simply too unreliable, and wireless telegraphy was confined to dots and dashes. And so, radio came on the market early in the 1920s, only fifteen years after the emergence of the knowledge on which it is based.</p>
<p class="para">Similarly, penicillin would probably not have been developed until the 1950s or so but for World War II. Alexander Fleming found the bacteria-killing mold, penicillium, in the mid-twenties. Howard Florey, an English biochemist, began to work on it ten years later. But it was World War II that forced the early introduction of penicillin. The need to have a potent drug to fight infections led the British government to push Florey’s research: English soldiers were made available to him as guinea pigs wherever they fought. The computer, too, would probably have waited for the discovery of the transistor by Bell Lab physicists in 1947 had not World War II led the American government to push computer research and to invest large resources of men and money in the work.</p>
<p class="para">The long lead time for knowledge-based innovations is by no means confined to science or technology. It applies equally to innovations that are based on nonscientific and nontechnological knowledge.</p>
<p class="para">The comte de Saint-Simon developed the theory of the entrepreneurial bank, the purposeful use of capital to generate economic <a id="page118" class="calibre"></a>development, right after the Napoleonic wars. Until then bankers were moneylenders who lent against “security” (e.g., the taxing power of a prince). Saint-Simon’s banker was to “invest,” that is, to create new wealth-producing capacity. Saint-Simon had extraordinary influence in his time, and a popular cult developed around his memory and his ideas after his death in 1826. Yet it was not until 1852 that two disciples, the brothers Jacob and Isaac Pereire, established the first entrepreneurial bank, the Credit Mobilier, and with it ushered in what we now call finance capitalism.</p>
<p class="para">Similarly, many of the elements needed for what we now call management were available right after World War I. Indeed, in 1923, Herbert Hoover, soon to be President of the United States, and Thomas Masaryk, founder and president of Czechoslovakia, convened the first International Management Congress in Prague. At the same time a few large companies here and there, especially DuPont and General Motors in the United States, began to reorganize themselves around the new management concepts. In the next decade a few “true believers,” especially an Englishman, Lyndall Urwick, the founder of the first management consulting firm which still bears his name, began to write on management. Yet it was not until my <span class="italic">Concept of the Corporation</span> (1946) and <span class="italic">Practice of Management</span> (1954) were published that management become a discipline accessible to managers all over the world. Until then each student or practitioner of “management” focused on a separate area; Urwick on organization, others on the management of people, and so on. My books codified it, organized it, systematized it. Within a few years, management became a worldwide force.</p>
<p class="para">Today, we experience a similar lead time in respect to learning theory. The scientific study of learning began around 1890 with Wilhelm Wundt in Germany and William James in the United States. After World War II, two Americans—B. F. Skinner and Jerome Bruner, both at Harvard—developed and tested basic theories of learning, Skinner specializing in behavior and Bruner in cognition. Yet only now is learning theory beginning to become a factor in our schools. Perhaps the time has come for an entrepreneur to start schools based on what we know about learning, rather than on the old wives’ tales about it that have been handed down through the ages.</p>
<p class="para">In other words, the lead time for knowledge to become applicable technology and begin to be accepted on the market is between twenty-five and thirty-five years.</p>
<a id="page119" class="calibre"></a>
<p class="para">This has not changed much throughout recorded history. It is widely believed that scientific discoveries turn much faster in our day than ever before into technology, products, and processes. But this is largely illusion. Around 1250 the Englishman Roger Bacon, a Franciscan monk, showed that refraction defects of the eye could be corrected with eyeglasses. This was incompatible with what everybody then knew: the “infallible” authority of the Middle Ages Galen, the great medical scientist, had “proven conclusively” that it could not be done. Roger Bacon lived and worked on the extreme edges of the civilized world, in the wilds of northern Yorkshire. Yet a mural, painted thirty years later in the Palace of the Popes in Avignon (where it can still be seen), shows elderly cardinals wearing reading glasses; and ten years later, miniatures show elderly courtiers in the Sultan’s Palace in Cairo also in glasses. The mill race, which was the first true “automation,” was developed to grind grain by the Benedictine monks in northern Europe around the year 1000; within thirty years it had spread all over Europe. Gutenberg’s invention of movable type and the woodcut both followed within thirty years of the West’s learning of Chinese printing.</p>
<p class="para">The lead time for knowledge to become knowledge-based innovation seems to be inherent in the nature of knowledge. We do not know why. But perhaps it is not pure coincidence that the same lead time applies to new scientific theory. Thomas Kuhn, in his path-breaking book <span class="italic">The Structure of Scientific Revolutions</span> (1962), showed that it takes about thirty years before a new scientific theory becomes a new paradigm—a new statement that scientists pay attention to and use in their own work.</p>
<p class="chapterHeadB1"><span class="smallCaps">CONVERGENCES</span></p>
<p class="para">The second characteristic of knowledge-based innovations—and a truly unique one—is that they are almost never based on one factor but on the convergence of several different kinds of knowledge, not all of them scientific or technological.</p>
<p class="para">Few knowledge-based innovations in this century have benefited humanity more than the hybridization of seeds and livestock. It enables the earth to feed a much larger population than anyone would have thought possible fifty years ago. The first successful new seed was hybrid corn. It was produced after twenty years of hard work by Henry C. <a id="page120" class="calibre"></a>Wallace, the publisher of a farm newspaper in Iowa, and later U.S. Secretary of Agriculture under Harding and Coolidge—the only holder of this office, perhaps, who deserves to be remembered for anything other than giving away money. Hybrid corn has two knowledge roots. One was the work of the Michigan plant breeder William J. Beal, who around 1880 discovered hybrid vigor. The other was the rediscovery of Mendel’s genetics by the Dutch biologist Hugo de Vries. The two men did not know of one another. Their work was totally different both in intent and content. But only by pulling it together could hybrid corn be developed.</p>
<p class="para">The Wright Brothers’ airplane also had two knowledge roots. One was the gasoline engine, designed in the mid-1880s to power the first automobiles built by Karl Benz and Gottfried Daimler, respectively. The other one was mathematical: aerodynamics, developed primarily in experiments with gliders. Each was developed quite independently. It was only when the two came together that the airplane became possible.</p>
<p class="para">The computer, as already noted, required the convergence of no less than five different knowledges: a scientific invention, the audion tube; a major mathematical discovery, the binary theorem; a new logic; the design concept of the punchcard; and the concepts of program and feedback. Until all these were available, no computer could have been built. Charles Babbage, the English mathematician, is often called the “father of the computer.” What kept Babbage from building a computer, it is argued, was only the unavailability of the proper metals and of electric power at his time. But this is a misunderstanding. Even if Babbage had had the proper materials, he could at best have built the mechanical calculator that we now call a cash register. Without the logic, the design concept of the punchcard, and the concept of program and feedback, none of which Babbage possessed, he could only imagine a computer.</p>
<p class="para">The Brothers Pereire founded the first entrepreneurial bank in 1852. It failed within a few years because they had only one knowledge base and the entrepreneurial bank needs two. They had a theory of creative finance that enabled them to be brilliant venture capitalists. But they lacked the systematic knowledge of banking which was developed at exactly the same time across the Channel by the British, and codified in Walter Bagehot’s classic, <span class="italic">Lombard Street.</span></p>
<p class="para">After their failure in the early 1860s, three young men independ<a id="page121" class="calibre"></a>ently picked up where the Brothers Pereire had left off, added the knowledge base of banking to the venture capital concept, and succeeded. The first was J. P. Morgan, who had been trained in London but had also carefully studied the Pereires’ Crédit Mobilier. He founded the most successful entrepreneurial bank of the nineteenth century in New York in 1865. The second one, across the Rhine, was the young German Georg Siemens, who founded what he called the “Universal Bank,” by which he meant a bank that was both a deposit bank on the British model and an entrepreneurial bank on the Pereires’ model. And in remote Tokyo, another young man, Shibusawa Eichii, who had been one of the first Japanese to travel to Europe to study banking first-hand, and had spent time both in Paris and in London’s Lombard Street, became one of the founders of the modern Japanese economy by establishing a Japanese version of the Universal Bank. Both Siemens’s Deutsche Bank and Shibusawa’s Daichi Bank are still the largest banks of their respective countries.</p>
<p class="para">The first man to envisage the modern newspaper was an American, James Gordon Bennett, who founded the <span class="italic">New York Herald.</span> Bennett fully understood the problems: A newspaper had to have enough income to be editorially independent and yet be cheap enough to have mass circulation. Earlier newspapers either got their income by selling their independence and becoming the lackeys and paid propagandists of a political faction—as did most American and practically all European papers of his time. Or, like the great aristocrat of those days, <span class="italic">The Times</span> of London, they were “written by gentlemen for gentlemen,” but so expensive that only a small elite could afford them.</p>
<p class="para">Bennett brilliantly exploited the twin technological knowledge bases on which a modern newspaper rests: the telegraph and high-speed printing. They enabled him to produce a paper at a fraction of the traditional cost. He knew that he needed high-speed typesetting, though it was not invented until after his death. He also saw one of the two nonscientific bases, mass literacy, which made possible mass circulation for a cheap newspaper. But he failed to grasp the fifth base: mass advertising as the source of the income that makes possible editorial independence. Bennett personally enjoyed a spectacular success; he was the first of the press lords. But his newspaper achieved neither leadership nor financial security. These goals were only attained two decades later, around 1890, by three men who understood and exploited advertising: Joseph Pulitzer, first in St. Louis and then in New <a id="page122" class="calibre"></a>York; Adolph Ochs, who took over a moribund <span class="italic">New York Times</span> and made it into America’s leading paper; and William Randolph Hearst, who invented the modern newspaper chain.</p>
<p class="para">The invention of plastics, beginning with Nylon, also rested on the convergence of a number of different new knowledges each emerging around 1910. Organic chemistry, pioneered by the Germans and perfected by Leo Baekeland, a Belgian working in New York, was one; X-Ray diffraction and with it an understanding of the structure of crystals was another; and high-vacuum technology. The final factor was the pressure of World War I shortages, which made the German government willing to invest heavily in polymerization research to obtain a substitute for rubber. It took a further twenty years, though, before Nylon was ready for the market.</p>
<p class="spaceBreak"> </p>
<p class="para">Until all the needed knowledges can be provided, knowledge-based innovation is premature and will fail. In most cases, the innovation occurs only when these various factors are already known, already available, already in use someplace. This was the case with the Universal Bank of 1865–75. It was the case with the computer after World War II. Sometimes the innovator can identify the missing pieces and then work at producing them. Joseph Pulitzer, Adolph Ochs, and William Randolph Hearst largely created modern advertising. This then created what we today call media, that is, the merger of information and advertising in “mass communications.” The Wright Brothers identified the pieces of knowledge that were missing—mostly mathematics—and then themselves developed them by building a wind tunnel and actually testing mathematical theories. But until all the knowledges needed for a given knowledge-based innovation have come together, the innovation will not take off. It will remain stillborn.</p>
<p class="para">Samuel Langley, for instance, whom his contemporaries expected to become the inventor of the airplane, was a much better trained scientist than the Wright Brothers. As secretary of what was then America’s leading scientific institution, the Smithsonian in Washington, he also had all the nation’s scientific resources at his disposal. But even though the gasoline engine had been invented by Langley’s time, he preferred to ignore it. He believed in the steam engine. As a result his airplane could fly; but because of the steam engine’s weight, it could not carry any load, let alone a pilot. It needed the convergence of mathematics and the gasoline engine to produce the airplane.</p>
<a id="page123" class="calibre"></a>
<p class="para">Indeed, until all the knowledges converge, the lead time of a knowledge-based innovation usually does not even begin.</p>
<p class="chapterHeadA">II</p>
<p class="chapterHeadB"><span class="smallCaps">WHAT KNOWLEDGE-BASED INNOVATION REQUIRES</span></p>
<p class="para">Its characteristics give knowledge-based innovation specific requirements. And these requirements differ from those of any other kind of innovation.</p>
<p class="para">1. In the first place, knowledge-based innovation requires careful <span class="italic">analysis</span> of all the necessary factors, whether knowledge itself, or social, economic, or perceptual factors. The analysis must identify what factors are not yet available so that the entrepreneur can decide whether these missing factors can be produced—as the Wright Brothers decided in respect to the missing mathematics—or whether the innovation had better be postponed as not yet feasible.</p>
<p class="para">The Wright Brothers exemplify the method at its best. They thought through carefully what knowledge was necessary to build an airplane for manned, motored flight. Next they set about to develop the pieces of knowledge that were needed, taking the available information, testing it first theoretically, then in the wind tunnel, and then in actual flight experiments, until they had the mathematics they needed to construct ailerons, to shape the wings, and so on.</p>
<p class="para">The same analysis is needed for nontechnical knowledge-based innovation. Neither J. P. Morgan nor Georg Siemens published their papers; but Shibusawa in Japan did. And so we know that he based his decision to forsake a brilliant government career and to start a bank on a careful analysis of the knowledge available and the knowledge needed. Similarly, Joseph Pulitzer analyzed carefully the knowledge needed when he launched what became the first modern newspaper, and decided that advertising had to be invented and could be invented.</p>
<p class="para">If I may inject a personal note, my own success as an innovator in the management field was based on a similar analysis in the early 1940s. Many of the required pieces of knowledge were already available: organization theory, for instance, but also quite a bit of knowledge about managing work and worker. My analysis also showed, however, that <a id="page124" class="calibre"></a>these pieces were scattered and lodged in half a dozen different disciplines. Then it found which key knowledges were missing: purpose of a business; any knowledge of the work and structure of top management; what we now term “business policy” and “strategy” objectives; and so on. All of the missing knowledges, I decided, could be produced. But without such analysis, I could never have known what they were or that they were missing.</p>
<p class="para">Failure to make such an analysis is an almost sure-fire prescription for disaster. Either the knowledge-based innovation is not achieved, which is what happened to Samuel Langley. Or the innovator loses the fruits of his innovation and only succeeds in creating an opportunity for somebody else.</p>
<p class="para">Particularly instructive is the failure of the British to reap the harvest from their own knowledge-based innovations.</p>
<p class="para">The British discovered and developed penicillin, but it was the Americans who took it over. The British scientists did a magnificent technical job. They came out with the right substances and the right uses. Yet they failed to identify the ability to manufacture the stuff as a critical knowledge factor. They could have developed the necessary knowledge of fermentation technology; they did not even try. As a result, a small American company, Pfizer, went to work on developing the knowledge of fermentation and became the world’s foremost manufacturer of penicillin.</p>
<p class="para">Similarly, the British conceived, designed, and built the first passenger jet plane. But de Havilland, the British company, did not analyze what was needed and therefore did not identify two key factors. One was configuration, that is, the right size with the right payload for the routes on which the jet would give an airline the greatest advantage. The other was equally mundane: how to finance the purchase of such an expensive plane by the airlines. As a result of de Havilland’s failure to do the analysis, two American companies, Boeing and Douglas, took over the jet plane. And de Havilland has long since disappeared.</p>
<p class="para">Such analysis would appear to be fairly obvious, yet it is rarely done by the scientific or technical innovator. Scientists and technologists are reluctant to make these analyses precisely because they think they already <span class="italic">know.</span> This explains why, in so many cases, the great knowledge-based innovations have had a layman rather than a scientist or a technologist for their father, or at least their godfather. The (American) General Electric Company is largely the brainchild of a financial man. <a id="page125" class="calibre"></a>He conceived the strategy (described in Chapter 19) that made G.E. the world’s leading supplier of large steam turbines and, therewith, the world’s leading supplier to electric power producers. Similarly, two laymen, Thomas Watson, Sr., and his son Thomas Watson, Jr., made IBM the leader in computers. At DuPont, the analysis of what was needed to make the knowledge-based innovation of Nylon effective and successful was not done by the chemist who developed the technology, but by business people on the executive committee. And Boeing became the world’s leading producer of jet planes under the leadership of marketing people who understood what the airlines and the public needed.</p>
<p class="para">This is not a law of nature, however. Mostly it is a matter of will and self-discipline. There have been plenty of scientists and technologists—Edison is a good example—who forced themselves to think through what their knowledge-based innovation required.</p>
<p class="para">2. The second requirement of knowledge-based innovation is a clear focus on the strategic position. It cannot be introduced tentatively. The fact that the introduction of the innovation creates excitement, and attracts a host of others, means that the innovator has to be right the first time. He is unlikely to get a second chance. In all the other innovations discussed so far, the innovator, once he has been successful with his innovation, can expect to be left alone for quite some time. This is not true of knowledge-based innovation. Here the innovators almost immediately have far more company than they want. They need only stumble once to be overrun.</p>
<p class="para">There are basically only three major focuses for knowledge-based innovation. First, there is the focus Edwin Land took with Polaroid: To develop a <span class="italic">complete system</span> that would then dominate the field. This is exactly what IBM did in its early years when it chose not to sell computers but to lease them to its customers. It supplied them with such software as was available, with programming, with instruction in computer language for programmers, with instruction in computer use for a customer’s executives, and with service. This was also what G.E. did when it established itself as the leader in the knowledge-based innovation of large steam turbines in the early years of this century.</p>
<p class="para">The second clear focus is a <span class="italic">market focus.</span> Knowledge-based innovation can aim at creating the market for its products. This is what DuPont did with Nylon. It did not “sell” Nylon; it created a consumer market for women’s hosiery and women’s underwear using Nylon, a market for automobile tires using Nylon, and so on. It then delivered Nylon to the <a id="page126" class="calibre"></a>fabricators to make the articles for which DuPont had already created a demand and which, in effect, it had already sold. Similarly, aluminum from the very beginning, right after the invention of the aluminum reduction process by Charles M. Hall in 1888, began to create a market for pots and pans, for rods and other aluminum extrusions. The aluminum company actually went into making these end products and selling them. It created the market which, in turn, discouraged (if it did not keep out altogether) potential competitors.</p>
<p class="para">The third focus is <span class="italic">to occupy a strategic position,</span> concentrating on a key function (the strategy is discussed in Chapter 18 under Ecological Niches). What position would enable the knowledge innovator to be largely immune to the extreme convolutions of a knowledge-based industry in its early stages? It was thinking this through and deciding to concentrate on mastering the fermentation process that gave Pfizer in the United States the early lead in penicillin it has maintained ever since. Focusing on marketing—on mastery of the requirements of airlines and of the public in respect to configuration and finance—gave Boeing the leadership in passenger planes, which it has held ever since. And despite the turbulence of the computer industry today, a few leading manufacturers of the computer’s key component, semiconductors, can maintain their leadership position almost irrespective of the fate of individual computer manufacturers themselves. Intel is one example.</p>
<p class="para">Within the same industry, individual knowledge-based innovators can sometimes choose between these alternatives. Where DuPont, for instance, has chosen to create markets, its closest American competitor, Dow Chemical, tries to occupy a key spot in each market segment. A hundred years ago, J. P. Morgan opted for the key function approach. He established his bank as the conduit for European investment capital in American industry, and furthermore in a capital-short country. At the same time, Georg Siemens in Germany and Shibusawa Eichii in Japan both went for the systems approach.</p>
<p class="para">The power of a clear focus is demonstrated by Edison’s success. Edison was not the only one who identified the inventions that had to be made to produce a light bulb. An English physicist, Joseph Swan, did so too. Swan developed <span class="italic">his</span> light bulb at exactly the same time as Edison. Technically, Swan’s bulb was superior, to the point where Edison bought up the Swan patents and used them in his own light bulb factories. But Edison not only thought through the technical requirements; <a id="page127" class="calibre"></a>he thought through his focus. Before he even began the technical work on the glass envelope, the vacuum, the closure, and the glowing fiber, he had already decided on a “system”: his light bulb was designed to fit an electric power company for which he had lined up the financing, the rights to string wires to get the power to his light bulb customers, and the distribution system. Swan, the scientist, invented a product; Edison produced an industry. So Edison could sell and install electric power while Swan was still trying to figure out who might be interested in his technical achievement.</p>
<p class="para">The knowledge-based innovator has to decide on a clear focus. Each of the three described here is admittedly very risky. But not to decide on a clear focus, let alone to try to be in between or to attempt more than one focus, is riskier by far. It is likely to prove fatal.</p>
<p class="para">3. Finally, the knowledge-based innovator—and especially the one whose innovation is based on scientific or technological knowledge—needs to learn and to practice entrepreneurial management (see Chapter 15, The New Venture). In fact, entrepreneurial management is more crucial to knowledge-based innovation than to any other kind. Its risks are high, thus putting a much higher premium on foresight, both financial and managerial, and on being market-focused and market-driven. Yet knowledge-based, and especially high-tech, innovation tends to have little entrepreneurial management. In large measure the high casualty rate of knowledge-based industry is the fault of the knowledge-based, and especially the high-tech, entrepreneurs themselves. They tend to be contemptuous of anything that is not “advanced knowledge,” and particularly of anyone who is not a specialist in their own area. They tend to be infatuated with their own technology, often believing that “quality” means what is technically sophisticated rather than what gives value to the user. In this respect they are still, by and large, nineteenth-century inventors rather than twentieth-century entrepreneurs.</p>
<p class="para">In fact, there are enough companies around today to show that the risk in knowledge-based innovation, including high tech, can be substantially reduced if entrepreneurial management is conscientiously applied. Hoffmann-LaRoche, the Swiss pharmaceutical company, is one example; Hewlett-Packard is another, and so is Intel. Precisely because the inherent risks of knowledge-based innovation are so high, entrepreneurial management is both particularly necessary and particularly effective.</p>
<a id="page128" class="calibre"></a>
<p class="chapterHeadA">III</p>
<p class="chapterHeadB"><span class="smallCaps">THE UNIQUE RISKS</span></p>
<p class="para">Even when it <span class="italic">is</span> based on meticulous analysis, endowed with clear focus, and conscientiously managed, knowledge-based innovation still suffers from unique risks and, worse, an innate unpredictability.</p>
<p class="para">First, by its very nature, it is turbulent.</p>
<p class="para">The combination of the two characteristics of knowledge-based innovations—long lead times and convergences—gives knowledge-based innovations their peculiar rhythm. For a long time, there is awareness of an innovation about to happen—but it does not happen. Then suddenly there is a near-explosion, followed by a few short years of tremendous excitement, tremendous startup activity, tremendous publicity. Five years later comes a “shakeout,” which few survive.</p>
<p class="para">In 1856, Werner Siemens in Germany applied the electrical theories Michael Faraday had developed around 1830 (twenty-five years earlier) to the design of the ancestor of the first electrical motor, the first dynamo. It caused a worldwide sensation. From then on, it became certain that there would be an “electrical industry” and that it would be a major one. Dozens of scientists and inventors went to work. But nothing happened for twenty-two years. The knowledge was missing: Maxwell’s development of Faraday’s theories.</p>
<p class="para">After it had become available, Edison invented the light bulb in 1878 and the race was on. Within the next five years all the major electrical apparatus companies in Europe and America were founded:</p>
<p class="para">Siemens in Germany bought up a small electrical apparatus manufacturer, Schuckert. The (German) General Electric Company, AEG, was formed on the basis of Edison’s work. In the United States there arose what are now G.E. and Westinghouse; in Switzerland, there was Brown Boveri; in Sweden, ASEA was founded in 1884. But these few are the survivors of a hundred such companies—American, British, French, German, Italian, Spanish, Dutch, Belgian, Swiss, Austrian, Czech, Hungarian, and so on—all eagerly financed by the investors of their time and all expecting to be “billion-dollar companies.” It was this upsurge of the electrical apparatus industry that gave rise to the first great science-fiction boom and made Jules Verne and H. C. Wells best-selling authors all over the world. But by 1895—1900, most of these companies <a id="page129" class="calibre"></a>had already disappeared, whether out of business, bankrupt, or absorbed by the few survivors.</p>
<p class="para">Around 1910, there were up to two hundred automobile companies in the United States alone. By the early 1930s, their number had shrunk to twenty, and by 1960 to four.</p>
<p class="para">In the 1920s, literally hundreds of companies were making radio sets and hundreds more were going into radio stations. By 1935, the control of broadcasting had moved into the hands of three “networks” and there were only a dozen manufacturers of radio sets left. Again, there was an explosion in the number of newspapers founded between 1880 and 1900. In fact, newspapers were among the major “growth industries” of the time. Since World War I, the number of newspapers in every major country has been going downhill steadily. And the same is true of banking. After the founders—the Morgans, the Siemenses, the Shibusawas—there was an almost explosive growth of new banks in the United States as well as in Europe. But around 1890, only twenty years later, consolidation set in. Banking firms began to go out of business or to merge. By the end of World War II in every major country only a handful of banks were left that had more than local importance, whether as commercial or private banks.</p>
<p class="para">But each time without exception the survivor has been a company that was started during the early explosive period. After that period is over, entry into the industry is foreclosed for all practical purposes. There is a “window” of a few years during which a new venture must establish itself in any new knowledge-based industry.</p>
<p class="para">It is commonly believed today that that “window” has become narrower. But this is as much a misconception as the common belief that the lead time between the emergence of new knowledge and its conversion into technology, products, and processes has become much shorter.</p>
<p class="para">Within a few years after George Stephenson’s “Rocket” had pulled the first train on a commercial railroad in 1830, over a hundred railroad companies were started in England. For ten years railroads were “high-tech” and railroad entrepreneurs “media events.” The speculative fever of these years is bitingly satirized in one of Dickens’s novels, <span class="italic">Little Dorrit</span> (published in 1855–57); it was not very different from today’s speculative fever in Silicon Valley. But around 1845, the “window” slammed shut. From then on there was no money in England any more for new railroads. Fifty years later, the hundred-or-so English railroad <a id="page130" class="calibre"></a>companies of 1845 had shrunk to five or six. And the same rhythm characterized the electrical apparatus industry, the telephone industry, the automobile industry, the chemical industry, household appliances, and consumer electronics. The “window” has never been very wide nor open very long.</p>
<p class="para">But there can be little doubt that today the “window” is becoming more and more crowded. The railroad boom of the 1830s was confined to England; later, every country had its own local boom quite separate from the preceding one in the neighboring country. The electrical apparatus boom already extended across national frontiers, as did the automobile boom twenty-five years later. Yet both were confined to the countries that were industrially developed at the time. The term “industrially developed” encompasses a great deal more territory today, however. It takes in Japan, for instance. It takes in Brazil. It may soon take in the non-Communist Chinese territories: Hong Kong, Taiwan, and Singapore. Communication today is practically instantaneous, travel easy and fast. And a great many countries have today what only very few small places had a hundred years ago: large cadres of trained people who can immediately go to work in any area of knowledge-based innovation, and especially of science-based or technology-based innovation.</p>
<p class="para">These facts have two important implications.</p>
<p class="para">1. First, science-based and technology-based innovators alike find time working against them. In all innovation based on any other source—the unexpected, incongruities, process need, changes in industry structure, demographics, or changes in perception—time is on the side of the innovator. In any other kind of innovation innovators can reasonably expect to be left alone. If they make a mistake, they are likely to have time to correct it. And there are several moments in time in which they can launch their new venture. Not so in knowledge-based innovation, and especially in those innovations based on scientific and technological knowledge. Here there is only a short time—the “window”—during which entry is possible at all. Here innovators do not get a second chance; they have to be right the first time. The environment is harsh and unforgiving. And once the “window” closes, the opportunity is gone forever.</p>
<p class="para">In some knowledge-based industries, however, a second “window” does in fact open some twenty to thirty years or so after the first one has shut down. Computers are an example.</p>
<a id="page131" class="calibre"></a>
<p class="para">The first “window” in computers lasted from 1949 until 1955 or so. During this period, every single electrical apparatus company in the world went into computers—G.E., Westinghouse, and RCA in the United States; the British General Electric Company, Plessey, and Ferranti in Great Britain; Siemens and AEG in Germany; Philips in Holland; and so on. By 1970, every single one of the “biggies” was out of computers, ignominiously. The field was occupied by companies that had either not existed at all in 1949 or had been small and marginal: IBM, of course, and the “Seven Dwarfs,” the seven smaller computer companies in the United States; ICL, the remnant of the computer businesses of the General Electric Company, of Plessey, and of Ferranti in Great Britain; some fragments sustained by heavy government subsidies in France; and a total newcomer, Nixdorf, in Germany. The Japanese companies were sustained for a long time through government support.</p>
<p class="para">Then, in the late seventies, a second “window” opened with the invention of micro-chips, which led to word processors, minicomputers, personal computers, and the merging of computer and telephone switchboard.</p>
<p class="para">But the companies that had failed in the first round did not come back in the second one. Even those that survived the first round stayed out of the second, or came in late and reluctantly. Neither Univac nor Control Data, nor Honeywell nor Burroughs, nor Fujitsu nor Hitachi took leadership in minicomputers or personal computers. The one exception was IBM, the undisputed champion of the first round. And this has been the pattern too in earlier knowledge-based innovations.</p>
<p class="para">2. Because the “window” is much more crowded, any one knowledge-based innovator has far less chance of survival.</p>
<p class="para">The number of entrants during the “window” period is likely to be much larger. But the structure of the industries, once they stabilize and mature, seems to have remained remarkably unchanged, at least for a century now. Of course there are great differences in structure between various industries, depending on technology, capital requirements, and ease of entry, on whether the product can be shipped or distributed only locally, and so on. But at any one time any given industry has a typical structure: in any given market there are so many companies altogether, so many big ones, so many medium-sized ones, so many small ones, so many specialists. And increasingly there is only <a id="page132" class="calibre"></a>one “market” for any new knowledge-based industry, whether computers or modern banking—the world market.</p>
<p class="para">The number of knowledge-based innovators that will survive when an industry matures and stabilizes <span class="italic">is</span> therefore no larger than it has traditionally been. But largely because of the emergence of a world market and of global communications, the number of entrants during the “window” period has greatly increased. When the shakeout comes, the casualty rate is therefore much higher than it used to be. And the shakeout always comes; <span class="italic">it</span> is inevitable.</p>
<p class="chapterHeadB1"><span class="smallCaps">THE SHAKEOUT</span></p>
<p class="para">The “shakeout” sets in as soon as the “window” closes. And the majority of ventures started during the “window” period do not survive the shakeout, as has already been shown for such high-tech industries of yesterday as railroads, electrical apparatus makers, and automobiles. As these lines are being written, the shakeout has begun among microprocessor, minicomputer, and personal computer companies—only five or six years after the “window” opened. Today, there are perhaps a hundred companies in the industry in the United States alone. Ten years hence, by 1995, there are unlikely to be more than a dozen left of any size or significance.</p>
<p class="para">But which ones will survive, which ones will die, and which ones will become permanently crippled—able neither to live nor to die—is unpredictable. In fact, it is futile to speculate. Sheer size may ensure survival. But it does not guarantee success in the shakeout, otherwise Allied Chemical rather than DuPont would today be the world’s biggest and most successful chemical company. In 1920, when the “window” opened for the chemical industry in the United States, Allied Chemical-looked invincible, if only because it had obtained the German chemical patents which the U.S. government had confiscated during World War I. Seven years later, after the shakeout, Allied Chemical had become a weak also-ran. It has never been able to regain momentum.</p>
<p class="para">No one in 1949 could have predicted that IBM would emerge as the computer giant, let alone that such big, experienced leaders as G.E. or Siemens would fail completely. No one in 1910 or 1914 when automobile stocks were the favorites of the New York Stock Exchange could have predicted that General Motors and Ford would survive and prosper <a id="page133" class="calibre"></a>and that such universal favorites as Packard or Hupmobile would disappear. No one in the 1870s and 1880s, the period in which the modern banks were born, could have predicted that Deutsche Bank would swallow up dozens of the old commercial banks of Germany and emerge as the leading bank of the country.</p>
<p class="para">That a certain industry will become important is fairly easy to predict. There is no case on record where an industry that reached the explosive phase, the “window” phase, as I called it, has then failed to become a major industry. The question is, Which of the specific units in this industry will be its leaders and so survive?</p>
<p class="spaceBreak"> </p>
<p class="para">This rhythm—a period of great excitement during which there is also great speculative ferment, followed by a severe “shakeout”—is particularly pronounced in the high-tech industries.</p>
<p class="para">In the first place, such industries are in the limelight and thus attract far more entrants and far more capital than more mundane areas. Also the expectations are much greater. More people have probably become rich building such prosaic businesses as a shoe-polish or a watchmaking company than have become rich through high-tech businesses. Yet no one expects shoe-polish makers to build a “billion-dollar business,” nor considers them a failure if all they build is a sound but modest family company. High tech, by contrast, is a “high—low game,” in which a middle hand is considered worthless. And this makes high-tech innovation inherently risky.</p>
<p class="para">But also, high tech is not profitable for a very long time. The world’s computer industry began in 1947–48. Not until the early 1980s, more than thirty years later, did the industry as a whole reach break-even point. To be sure, a few companies (practically all of them American, by the way) began to make money much earlier. And one, IBM, the leader, began to make a great deal of money earlier still. But across the industry the profits of those few successful computer makers were more than offset by the horrendous losses of the rest; the enormous losses, for instance, which the big international electrical companies took in their abortive attempts to become computer manufacturers.</p>
<p class="para">And exactly the same thing happened in every earlier “high-tech” boom—in the railroad booms of the early nineteenth century, in the electrical apparatus and the automobile booms between 1880 and 1914, in the electric appliance and the radio booms of the 1920s, and so on.</p>
<a id="page134" class="calibre"></a>
<p class="para">One major reason for this is the need to plow more and more money back into research, technical development, and technical services to stay in the race. High tech does indeed have to run faster and faster in order to stand still.</p>
<p class="para">This is, of course, part of its fascination. But it also means that when the shakeout comes, very few businesses in the industry have the financial resources to outlast even a short storm. This is the reason why high-tech ventures need financial foresight even more than other new ventures, but also the reason why financial foresight is even scarcer among high-tech new ventures than it is among new ventures in general.</p>
<p class="para">There is only one prescription for survival during the shakeout: entrepreneurial management (described in Chapters 12–15). What distinguished Deutsche Bank from the other “hot” financial institutions of its time was that Georg Siemens thought through and built the world’s first top management team. What distinguished DuPont from Allied Chemical was that DuPont in the early twenties created the world’s first systematic organization structure, the world’s first long-range planning, and the world’s first system of management information and control. Allied Chemical, by contrast, was run arbitrarily by one brilliant egomaniac. But this is not the whole story. Most of the large companies that failed to survive the more recent computer shakeout—G.E. and Siemens, for instance—are usually considered to have first-rate management. And the Ford Motor Company survived, though only by the skin of its teeth, even though it was grotesquely mismanaged during the shakeout years.</p>
<p class="para">Entrepreneurial management is thus probably a precondition of survival, but not a guarantee thereof. And at the time of the shakeout, only insiders (and perhaps not even they) can really know whether a knowledge-based innovator that has grown rapidly for a few boom years is well managed, as DuPont was, or basically unmanaged, as Allied Chemical was. By the time we do know, it is likely to be too late.</p>
<p class="chapterHeadB1"><span class="smallCaps">THE RECEPTIVITY GAMBLE</span></p>
<p class="para">To be successful, a knowledge-based innovation has to be “ripe” there has to be receptivity to it. This risk is inherent in knowledge based innovation and is indeed a function of its unique power. All other <a id="page135" class="calibre"></a>innovations exploit a change that has already occurred. They satisfy a need that already exists. But in knowledge-based innovation, the innovation brings about the change. It aims at creating a want. And no one can tell in advance whether the user is going to be receptive, indifferent, or actively resistant.</p>
<p class="para">There are exceptions, to be sure. Whoever produces a cure for cancer need not worry about “receptivity.” But such exceptions are few. Inmost knowledge-based innovations, receptivity is a gamble. And the odds are unknown, are indeed mysterious. There may be great receptivity, yet no one realizes it. And there may be no receptivity, or even heavy resistance when everyone is quite sure that society is actually eagerly waiting for the innovation.</p>
<p class="para">Stories of the obtuseness of the high and mighty in the face of a knowledge-based innovation abound. Typical is the anecdote which has a king of Prussia predicting the certain failure of that new-fangled contraption, the railroad, because “No one will pay good money to get from Berlin to Potsdam in one hour when he can ride his horse in one day for free.” But the king of Prussia was not alone in his misreading of the receptivity to the railroad; the majority of the “experts” of his day inclined to his opinion. And when the computer appeared there was not one single “expert” who could imagine that businesses would ever want such a contraption.</p>
<p class="para">The opposite error is, however, just as common. “Everybody knows” that there is a real need, a real demand, when in reality there is total indifference or resistance. The same authorities who, in 1948, could not imagine that a business would ever want a computer, a few years later, around 1955, predicted that the computer would “revolutionize the schools” within a decade.</p>
<p class="para">The Germans consider Philip Reis rather than Alexander Graham Bell to be the inventor of the telephone. Reis did indeed build an instrument in 1861 that could transmit music and was very close to transmitting speech. But then he gave up, totally discouraged. There was no receptivity for a telephone, no interest in it, no desire for it. “The telegraph is good enough for us,” was the prevailing attitude. Yet when Bell, fifteen years later, patented his telephone, there was an immediate enthusiastic response. And nowhere was it greater than in Germany.</p>
<p class="para">The change in receptivity in these fifteen years is not too difficult to explain. Two major wars, the American Civil War and the Franco-<a id="page136" class="calibre"></a>Prussian War, had shown that the telegraph was by no means “good enough.” But the real point is not why receptivity changed. It is that every authority in 1861 enthusiastically predicted overwhelming receptivity when Reis demonstrated his instrument at a scientific meeting. And every authority was wrong.</p>
<p class="para">But, of course, the authorities can also be right, and often are. In 1876–77, for instance, they all knew that there was receptivity for both a light bulb and a telephone—and they were right. Similarly, Edison, in the 1880s, was supported by the expert opinion of his time when he embarked on the invention of the phonograph, and again the experts were right in assuming high receptivity for the new device.</p>
<p class="para">But only hindsight can tell us whether the experts are right or wrong in their assessment of the receptivity for this or that knowledge-based innovation.</p>
<p class="para">Nor do we necessarily perceive, even by hindsight, why a particular knowledge-based innovation has receptivity or fails to find it. No one, for instance, can explain why phonetic spelling has been so strenuously resisted. Everyone agrees that nonphonetic spelling is a major obstacle in learning to read and write, forces schools to devote inordinate time to the reading skill, and is responsible for a disproportionate number of reading disabilities and emotional traumas among children. The knowledge of phonetics is a century old at least. Means to achieve phonetic spelling are available in the two languages where the problem is most acute: any number of phonetic alphabets for English, and the much older, forty-eight-syllable Kana scripts in Japanese. For both countries there are examples next door of a successful shift to a phonetic script. The English have the successful model of German spelling reform of the mid-nineteenth century; the Japanese, the equally successful—and much earlier—phonetic reform of the Korean script. Yet in neither country is there the slightest receptivity for an innovation that, one would say, is badly needed, eminently rational, and proven by example to be safe, fairly easy, and efficacious. Why? Explanations abound, but no one really knows.</p>
<p class="para">There is no way to eliminate the element of risk, no way even to reduce it. Market research does not work—one cannot do market research on something that does not exist. Opinion research is probably not just useless but likely to do damage. At least this is what the experience with “expert opinion” on the receptivity to knowledge-based innovation would indicate.</p>
<a id="page137" class="calibre"></a>
<p class="para">Yet there is no choice. If we want knowledge-based innovation, we must gamble on receptivity to it.</p>
<p class="spaceBreak"> </p>
<p class="para">The risks are highest in innovations based on new knowledge in science and technology. They are particularly high, of course, in innovations in areas that are currently “hot”—personal computers, at the present time, or biotechnology. By contrast, areas that are not in the public eye have far lower risks, if only because there is more time. And in innovations where the knowledge base is not science or technology—social innovations, for instance—the risks are lower still. But high risk is inherent in knowledge-based innovation. It is the price we have to pay for its impact and above all for its capacity to bring about change, not only in products and services but in how we see the world, our place in it, and eventually ourselves.</p>
<p class="para">Yet the risks even of high-tech innovation can be substantially reduced by integrating new knowledge as the source of innovation with one of the other sources defined earlier, the unexpected, incongruities, and especially process need. In these areas receptivity has either already been established or can be tested fairly easily and with good reliability. And in these areas, too, the knowledge or knowledges that have to be produced to complete an innovation can usually be defined with considerable precision. This is the reason why “program research” is becoming so popular. But even program research requires a great deal of system and self-discipline, and has to be organized and purposeful.</p>
<p class="para">The demands on knowledge-based innovators are thus very great. They are also different from those in other areas of innovation. The risks they face are different, too; time, for instance, is not on their side. But if the risks are greater, so are the potential rewards. The other innovators may reap a fortune. The knowledge-based innovator can hope for fame as well.</p>
</div>
</div></div>

{% endraw %}

